Start samsung
End load_stock_and_preprocessing !

IN make_train_test_set 
train_data X shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 20, 1)
train_data Y shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 1)
valid_data X shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 20, 1)
valid_data Y shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 1)
test_data X shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 20, 1)
test_data Y shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 1)

End make_train_test_set !

IN make_model, print model <tensorflow.python.keras.engine.sequential.Sequential object at 0x7fae10154050>
IN learning, print model <tensorflow.python.keras.engine.sequential.Sequential object at 0x7fae10154050>
train_data X shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 20, 1)
train_data Y shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 1)
valid_data X shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 20, 1)
valid_data Y shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 1)
Epoch 1/50

      1/Unknown - 4s 4s/step - loss: 0.0256 - mse: 0.0512
      9/Unknown - 4s 7ms/step - loss: 0.0258 - mse: 0.0515
9/9 [==============================] - 4s 76ms/step - loss: 0.0255 - mse: 0.0511 - val_loss: 0.0131 - val_mse: 0.0263

Epoch 00001: val_loss improved from inf to 0.01314, saving model to ./model/models/005930/005930.ckpt
Epoch 2/50

1/9 [==>...........................] - ETA: 0s - loss: 0.0156 - mse: 0.0312
9/9 [==============================] - 0s 8ms/step - loss: 0.0135 - mse: 0.0270 - val_loss: 0.0039 - val_mse: 0.0078

Epoch 00002: val_loss improved from 0.01314 to 0.00392, saving model to ./model/models/005930/005930.ckpt
Epoch 3/50

1/9 [==>...........................] - ETA: 0s - loss: 0.0042 - mse: 0.0084
9/9 [==============================] - 0s 9ms/step - loss: 0.0042 - mse: 0.0084 - val_loss: 6.1660e-04 - val_mse: 0.0012

Epoch 00003: val_loss improved from 0.00392 to 0.00062, saving model to ./model/models/005930/005930.ckpt
Epoch 4/50

1/9 [==>...........................] - ETA: 0s - loss: 0.0013 - mse: 0.0027
9/9 [==============================] - 0s 9ms/step - loss: 0.0016 - mse: 0.0032 - val_loss: 0.0012 - val_mse: 0.0025

Epoch 00004: val_loss did not improve from 0.00062
Epoch 5/50

1/9 [==>...........................] - ETA: 0s - loss: 0.0020 - mse: 0.0040
9/9 [==============================] - 0s 9ms/step - loss: 0.0018 - mse: 0.0036 - val_loss: 6.4270e-04 - val_mse: 0.0013

Epoch 00005: val_loss did not improve from 0.00062
Epoch 6/50

1/9 [==>...........................] - ETA: 0s - loss: 0.0014 - mse: 0.0029
9/9 [==============================] - 0s 9ms/step - loss: 0.0012 - mse: 0.0023 - val_loss: 6.4164e-04 - val_mse: 0.0013

Epoch 00006: val_loss did not improve from 0.00062
Epoch 7/50

1/9 [==>...........................] - ETA: 0s - loss: 7.5272e-04 - mse: 0.0015
9/9 [==============================] - 0s 9ms/step - loss: 7.7374e-04 - mse: 0.0015 - val_loss: 7.5831e-04 - val_mse: 0.0015

Epoch 00007: val_loss did not improve from 0.00062
Epoch 8/50

1/9 [==>...........................] - ETA: 0s - loss: 5.2996e-04 - mse: 0.0011
9/9 [==============================] - 0s 9ms/step - loss: 7.4148e-04 - mse: 0.0015 - val_loss: 6.4266e-04 - val_mse: 0.0013

Epoch 00008: val_loss did not improve from 0.00062
Epoch 9/50

1/9 [==>...........................] - ETA: 0s - loss: 6.1136e-04 - mse: 0.0012
9/9 [==============================] - 0s 9ms/step - loss: 5.6509e-04 - mse: 0.0011 - val_loss: 6.2376e-04 - val_mse: 0.0012

Epoch 00009: val_loss did not improve from 0.00062
Epoch 10/50

1/9 [==>...........................] - ETA: 0s - loss: 6.7282e-04 - mse: 0.0013
9/9 [==============================] - 0s 9ms/step - loss: 5.6311e-04 - mse: 0.0011 - val_loss: 7.2054e-04 - val_mse: 0.0014

Epoch 00010: val_loss did not improve from 0.00062
Epoch 11/50

1/9 [==>...........................] - ETA: 0s - loss: 5.0080e-04 - mse: 0.0010
9/9 [==============================] - 0s 9ms/step - loss: 4.4686e-04 - mse: 8.9372e-04 - val_loss: 6.4841e-04 - val_mse: 0.0013

Epoch 00011: val_loss did not improve from 0.00062
Epoch 12/50

1/9 [==>...........................] - ETA: 0s - loss: 5.7201e-04 - mse: 0.0011
9/9 [==============================] - 0s 8ms/step - loss: 4.7425e-04 - mse: 9.4851e-04 - val_loss: 7.4232e-04 - val_mse: 0.0015

Epoch 00012: val_loss did not improve from 0.00062
Epoch 13/50

1/9 [==>...........................] - ETA: 0s - loss: 4.4711e-04 - mse: 8.9422e-04
9/9 [==============================] - 0s 8ms/step - loss: 4.6298e-04 - mse: 9.2595e-04 - val_loss: 6.7357e-04 - val_mse: 0.0013

Epoch 00013: val_loss did not improve from 0.00062
End learning !
End make_model !

005930 Start check_bias_variance !
Test about valid_set
End load_moodel !

End prediction !

len_ori : 50, len_pred : 50
======= difference ======= 
idx : 1, pred - ori : 0.145912
idx : 2, pred - ori : 0.052717
idx : 3, pred - ori : 0.015542
idx : 4, pred - ori : 0.025625
idx : 5, pred - ori : 0.013864
idx : 6, pred - ori : 0.022228
idx : 7, pred - ori : 0.023029
idx : 8, pred - ori : 0.058464
idx : 9, pred - ori : 0.037098
idx : 10, pred - ori : 0.031111
idx : 11, pred - ori : -0.003822
idx : 12, pred - ori : -0.021414
idx : 13, pred - ori : -0.002929
idx : 14, pred - ori : -0.011530
idx : 15, pred - ori : -0.012836
idx : 16, pred - ori : 0.005773
idx : 17, pred - ori : -0.006632
idx : 18, pred - ori : -0.005343
idx : 19, pred - ori : -0.049369
idx : 20, pred - ori : -0.022318
idx : 21, pred - ori : -0.004741
idx : 22, pred - ori : -0.012688
idx : 23, pred - ori : -0.011279
idx : 24, pred - ori : -0.001430
idx : 25, pred - ori : -0.010029
idx : 26, pred - ori : -0.014001
idx : 27, pred - ori : -0.011592
idx : 28, pred - ori : 0.017116
idx : 29, pred - ori : 0.004678
idx : 30, pred - ori : 0.012940
idx : 31, pred - ori : 0.012424
idx : 32, pred - ori : 0.019569
idx : 33, pred - ori : 0.028036
idx : 34, pred - ori : 0.015156
idx : 35, pred - ori : 0.024593
idx : 36, pred - ori : 0.026084
idx : 37, pred - ori : 0.007839
idx : 38, pred - ori : -0.020691
idx : 39, pred - ori : -0.015068
idx : 40, pred - ori : -0.014148
idx : 41, pred - ori : 0.009496
idx : 42, pred - ori : 0.008127
idx : 43, pred - ori : 0.000998
idx : 44, pred - ori : -0.011523
idx : 45, pred - ori : -0.020682
idx : 46, pred - ori : -0.025830
idx : 47, pred - ori : -0.034235
idx : 48, pred - ori : -0.036630
idx : 49, pred - ori : -0.092762
idx : 50, pred - ori : -0.091696
result_sum : 1.183637, mean(result_sum) : 0.023673
benefit : 26

 End check_performance !

Test about test_set
End load_moodel !

End prediction !

len_ori : 180, len_pred : 180
======= difference ======= 
idx : 1, pred - ori : -0.048779
idx : 2, pred - ori : -0.075255
idx : 3, pred - ori : -0.044687
idx : 4, pred - ori : -0.037656
idx : 5, pred - ori : -0.033366
idx : 6, pred - ori : -0.031493
idx : 7, pred - ori : -0.043773
idx : 8, pred - ori : -0.050548
idx : 9, pred - ori : -0.067115
idx : 10, pred - ori : -0.049477
idx : 11, pred - ori : -0.060552
idx : 12, pred - ori : -0.055471
idx : 13, pred - ori : -0.075395
idx : 14, pred - ori : -0.062223
idx : 15, pred - ori : -0.050730
idx : 16, pred - ori : -0.051275
idx : 17, pred - ori : -0.076817
idx : 18, pred - ori : -0.131369
idx : 19, pred - ori : -0.136913
idx : 20, pred - ori : -0.135093
idx : 21, pred - ori : -0.111536
idx : 22, pred - ori : -0.088272
idx : 23, pred - ori : -0.094647
idx : 24, pred - ori : -0.084484
idx : 25, pred - ori : -0.103491
idx : 26, pred - ori : -0.092138
idx : 27, pred - ori : -0.096990
idx : 28, pred - ori : -0.102632
idx : 29, pred - ori : -0.116470
idx : 30, pred - ori : -0.109169
idx : 31, pred - ori : -0.094888
idx : 32, pred - ori : -0.100969
idx : 33, pred - ori : -0.088105
idx : 34, pred - ori : -0.042613
idx : 35, pred - ori : -0.052111
idx : 36, pred - ori : -0.055144
idx : 37, pred - ori : -0.061292
idx : 38, pred - ori : -0.062119
idx : 39, pred - ori : -0.048844
idx : 40, pred - ori : -0.046690
idx : 41, pred - ori : -0.021817
idx : 42, pred - ori : -0.027464
idx : 43, pred - ori : -0.032225
idx : 44, pred - ori : -0.071731
idx : 45, pred - ori : -0.057963
idx : 46, pred - ori : -0.076550
idx : 47, pred - ori : -0.117579
idx : 48, pred - ori : -0.111735
idx : 49, pred - ori : -0.126138
idx : 50, pred - ori : -0.120993
idx : 51, pred - ori : -0.145972
idx : 52, pred - ori : -0.154104
idx : 53, pred - ori : -0.152260
idx : 54, pred - ori : -0.121575
idx : 55, pred - ori : -0.115536
idx : 56, pred - ori : -0.110637
idx : 57, pred - ori : -0.090060
idx : 58, pred - ori : -0.096432
idx : 59, pred - ori : -0.080684
idx : 60, pred - ori : -0.082675
idx : 61, pred - ori : -0.087809
idx : 62, pred - ori : -0.087766
idx : 63, pred - ori : -0.096804
idx : 64, pred - ori : -0.102202
idx : 65, pred - ori : -0.118932
idx : 66, pred - ori : -0.114267
idx : 67, pred - ori : -0.126989
idx : 68, pred - ori : -0.135253
idx : 69, pred - ori : -0.134337
idx : 70, pred - ori : -0.116229
idx : 71, pred - ori : -0.106066
idx : 72, pred - ori : -0.114507
idx : 73, pred - ori : -0.130617
idx : 74, pred - ori : -0.130140
idx : 75, pred - ori : -0.114943
idx : 76, pred - ori : -0.116490
idx : 77, pred - ori : -0.119376
idx : 78, pred - ori : -0.107295
idx : 79, pred - ori : -0.092064
idx : 80, pred - ori : -0.075210
idx : 81, pred - ori : -0.047461
idx : 82, pred - ori : -0.063389
idx : 83, pred - ori : -0.090199
idx : 84, pred - ori : -0.086259
idx : 85, pred - ori : -0.121394
idx : 86, pred - ori : -0.118021
idx : 87, pred - ori : -0.120717
idx : 88, pred - ori : -0.119936
idx : 89, pred - ori : -0.140457
idx : 90, pred - ori : -0.133486
idx : 91, pred - ori : -0.174048
idx : 92, pred - ori : -0.229560
idx : 93, pred - ori : -0.216216
idx : 94, pred - ori : -0.197269
idx : 95, pred - ori : -0.190083
idx : 96, pred - ori : -0.188027
idx : 97, pred - ori : -0.236312
idx : 98, pred - ori : -0.236209
idx : 99, pred - ori : -0.213570
idx : 100, pred - ori : -0.236351
idx : 101, pred - ori : -0.235720
idx : 102, pred - ori : -0.203688
idx : 103, pred - ori : -0.220807
idx : 104, pred - ori : -0.248975
idx : 105, pred - ori : -0.249509
idx : 106, pred - ori : -0.280567
idx : 107, pred - ori : -0.303295
idx : 108, pred - ori : -0.277377
idx : 109, pred - ori : -0.314723
idx : 110, pred - ori : -0.290531
idx : 111, pred - ori : -0.296684
idx : 112, pred - ori : -0.298897
idx : 113, pred - ori : -0.296525
idx : 114, pred - ori : -0.292796
idx : 115, pred - ori : -0.280605
idx : 116, pred - ori : -0.272233
idx : 117, pred - ori : -0.269586
idx : 118, pred - ori : -0.254767
idx : 119, pred - ori : -0.283561
idx : 120, pred - ori : -0.354536
idx : 121, pred - ori : -0.369874
idx : 122, pred - ori : -0.360886
idx : 123, pred - ori : -0.408487
idx : 124, pred - ori : -0.440899
idx : 125, pred - ori : -0.452906
idx : 126, pred - ori : -0.416097
idx : 127, pred - ori : -0.425451
idx : 128, pred - ori : -0.529234
idx : 129, pred - ori : -0.563224
idx : 130, pred - ori : -0.551385
idx : 131, pred - ori : -0.529195
idx : 132, pred - ori : -0.523386
idx : 133, pred - ori : -0.483474
idx : 134, pred - ori : -0.422172
idx : 135, pred - ori : -0.456211
idx : 136, pred - ori : -0.456170
idx : 137, pred - ori : -0.472640
idx : 138, pred - ori : -0.446434
idx : 139, pred - ori : -0.494439
idx : 140, pred - ori : -0.440467
idx : 141, pred - ori : -0.420794
idx : 142, pred - ori : -0.382848
idx : 143, pred - ori : -0.351660
idx : 144, pred - ori : -0.370644
idx : 145, pred - ori : -0.398452
idx : 146, pred - ori : -0.404640
idx : 147, pred - ori : -0.367384
idx : 148, pred - ori : -0.387766
idx : 149, pred - ori : -0.378414
idx : 150, pred - ori : -0.375195
idx : 151, pred - ori : -0.355969
idx : 152, pred - ori : -0.406834
idx : 153, pred - ori : -0.420073
idx : 154, pred - ori : -0.390428
idx : 155, pred - ori : -0.370412
idx : 156, pred - ori : -0.379657
idx : 157, pred - ori : -0.372007
idx : 158, pred - ori : -0.369717
idx : 159, pred - ori : -0.370866
idx : 160, pred - ori : -0.433893
idx : 161, pred - ori : -0.381354
idx : 162, pred - ori : -0.404315
idx : 163, pred - ori : -0.409370
idx : 164, pred - ori : -0.379861
idx : 165, pred - ori : -0.373910
idx : 166, pred - ori : -0.371999
idx : 167, pred - ori : -0.361188
idx : 168, pred - ori : -0.352514
idx : 169, pred - ori : -0.374080
idx : 170, pred - ori : -0.389460
idx : 171, pred - ori : -0.371686
idx : 172, pred - ori : -0.391133
idx : 173, pred - ori : -0.381310
idx : 174, pred - ori : -0.393284
idx : 175, pred - ori : -0.373909
idx : 176, pred - ori : -0.376464
idx : 177, pred - ori : -0.372004
idx : 178, pred - ori : -0.357488
idx : 179, pred - ori : -0.361509
idx : 180, pred - ori : -0.367409
result_sum : 40.291286, mean(result_sum) : 0.223840
benefit : 180

 End check_performance !

Finish samsung
Start sk
End load_stock_and_preprocessing !

IN make_train_test_set 
train_data X shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 20, 1)
train_data Y shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 1)
valid_data X shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 20, 1)
valid_data Y shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 1)
test_data X shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 20, 1)
test_data Y shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 1)

End make_train_test_set !

IN make_model, print model <tensorflow.python.keras.engine.sequential.Sequential object at 0x7fadcbab2590>
IN learning, print model <tensorflow.python.keras.engine.sequential.Sequential object at 0x7fadcbab2590>
train_data X shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 20, 1)
train_data Y shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 1)
valid_data X shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 20, 1)
valid_data Y shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 1)
Epoch 1/50

      1/Unknown - 1s 1s/step - loss: 0.0321 - mse: 0.0642
9/9 [==============================] - 2s 50ms/step - loss: 0.0231 - mse: 0.0463 - val_loss: 0.0081 - val_mse: 0.0161

Epoch 00001: val_loss improved from inf to 0.00806, saving model to ./model/models/000660/000660.ckpt
Epoch 2/50

1/9 [==>...........................] - ETA: 0s - loss: 0.0097 - mse: 0.0194
9/9 [==============================] - 0s 9ms/step - loss: 0.0067 - mse: 0.0133 - val_loss: 5.6658e-04 - val_mse: 0.0011

Epoch 00002: val_loss improved from 0.00806 to 0.00057, saving model to ./model/models/000660/000660.ckpt
Epoch 3/50

1/9 [==>...........................] - ETA: 0s - loss: 0.0015 - mse: 0.0029
9/9 [==============================] - 0s 9ms/step - loss: 0.0021 - mse: 0.0041 - val_loss: 0.0014 - val_mse: 0.0029

Epoch 00003: val_loss did not improve from 0.00057
Epoch 4/50

1/9 [==>...........................] - ETA: 0s - loss: 0.0022 - mse: 0.0045
9/9 [==============================] - 0s 9ms/step - loss: 0.0023 - mse: 0.0046 - val_loss: 5.6195e-04 - val_mse: 0.0011

Epoch 00004: val_loss improved from 0.00057 to 0.00056, saving model to ./model/models/000660/000660.ckpt
Epoch 5/50

1/9 [==>...........................] - ETA: 0s - loss: 0.0020 - mse: 0.0041
9/9 [==============================] - 0s 9ms/step - loss: 0.0018 - mse: 0.0036 - val_loss: 8.3921e-04 - val_mse: 0.0017

Epoch 00005: val_loss did not improve from 0.00056
Epoch 6/50

1/9 [==>...........................] - ETA: 0s - loss: 0.0027 - mse: 0.0055
9/9 [==============================] - 0s 9ms/step - loss: 0.0020 - mse: 0.0041 - val_loss: 5.6755e-04 - val_mse: 0.0011

Epoch 00006: val_loss did not improve from 0.00056
Epoch 7/50

1/9 [==>...........................] - ETA: 0s - loss: 0.0019 - mse: 0.0038
9/9 [==============================] - 0s 8ms/step - loss: 0.0017 - mse: 0.0034 - val_loss: 5.9071e-04 - val_mse: 0.0012

Epoch 00007: val_loss did not improve from 0.00056
Epoch 8/50

1/9 [==>...........................] - ETA: 0s - loss: 0.0020 - mse: 0.0040
9/9 [==============================] - 0s 8ms/step - loss: 0.0016 - mse: 0.0032 - val_loss: 5.7777e-04 - val_mse: 0.0012

Epoch 00008: val_loss did not improve from 0.00056
Epoch 9/50

1/9 [==>...........................] - ETA: 0s - loss: 0.0013 - mse: 0.0026
9/9 [==============================] - 0s 10ms/step - loss: 0.0012 - mse: 0.0025 - val_loss: 5.8310e-04 - val_mse: 0.0012

Epoch 00009: val_loss did not improve from 0.00056
Epoch 10/50

1/9 [==>...........................] - ETA: 0s - loss: 9.3350e-04 - mse: 0.0019
9/9 [==============================] - 0s 8ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 6.1188e-04 - val_mse: 0.0012

Epoch 00010: val_loss did not improve from 0.00056
Epoch 11/50

1/9 [==>...........................] - ETA: 0s - loss: 0.0010 - mse: 0.0021
9/9 [==============================] - 0s 9ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 6.4318e-04 - val_mse: 0.0013

Epoch 00011: val_loss did not improve from 0.00056
Epoch 12/50

1/9 [==>...........................] - ETA: 0s - loss: 0.0011 - mse: 0.0021
9/9 [==============================] - 0s 9ms/step - loss: 0.0010 - mse: 0.0020 - val_loss: 6.0489e-04 - val_mse: 0.0012

Epoch 00012: val_loss did not improve from 0.00056
Epoch 13/50

1/9 [==>...........................] - ETA: 0s - loss: 0.0013 - mse: 0.0026
9/9 [==============================] - 0s 8ms/step - loss: 9.9771e-04 - mse: 0.0020 - val_loss: 6.1390e-04 - val_mse: 0.0012

Epoch 00013: val_loss did not improve from 0.00056
Epoch 14/50

1/9 [==>...........................] - ETA: 0s - loss: 8.6528e-04 - mse: 0.0017
9/9 [==============================] - 0s 9ms/step - loss: 9.1155e-04 - mse: 0.0018 - val_loss: 6.2697e-04 - val_mse: 0.0013

Epoch 00014: val_loss did not improve from 0.00056
End learning !
End make_model !

000660 Start check_bias_variance !
Test about valid_set
End load_moodel !

End prediction !

len_ori : 50, len_pred : 50
======= difference ======= 
idx : 1, pred - ori : 0.169383
idx : 2, pred - ori : 0.054974
idx : 3, pred - ori : -0.024078
idx : 4, pred - ori : 0.007707
idx : 5, pred - ori : -0.026029
idx : 6, pred - ori : -0.032934
idx : 7, pred - ori : -0.025185
idx : 8, pred - ori : 0.032313
idx : 9, pred - ori : 0.017205
idx : 10, pred - ori : 0.023498
idx : 11, pred - ori : -0.013776
idx : 12, pred - ori : -0.044497
idx : 13, pred - ori : -0.031403
idx : 14, pred - ori : -0.035807
idx : 15, pred - ori : -0.023378
idx : 16, pred - ori : 0.010937
idx : 17, pred - ori : 0.005041
idx : 18, pred - ori : 0.018543
idx : 19, pred - ori : -0.010043
idx : 20, pred - ori : 0.013416
idx : 21, pred - ori : 0.021365
idx : 22, pred - ori : -0.006802
idx : 23, pred - ori : 0.007270
idx : 24, pred - ori : 0.020843
idx : 25, pred - ori : 0.007127
idx : 26, pred - ori : -0.001962
idx : 27, pred - ori : -0.005144
idx : 28, pred - ori : 0.024238
idx : 29, pred - ori : 0.009212
idx : 30, pred - ori : 0.009704
idx : 31, pred - ori : -0.018346
idx : 32, pred - ori : -0.013620
idx : 33, pred - ori : -0.027282
idx : 34, pred - ori : -0.003712
idx : 35, pred - ori : 0.031058
idx : 36, pred - ori : 0.018897
idx : 37, pred - ori : 0.028772
idx : 38, pred - ori : 0.011403
idx : 39, pred - ori : -0.006025
idx : 40, pred - ori : -0.000309
idx : 41, pred - ori : 0.022189
idx : 42, pred - ori : 0.021010
idx : 43, pred - ori : 0.015917
idx : 44, pred - ori : 0.021723
idx : 45, pred - ori : -0.006572
idx : 46, pred - ori : 0.018230
idx : 47, pred - ori : -0.005409
idx : 48, pred - ori : -0.002682
idx : 49, pred - ori : -0.061535
idx : 50, pred - ori : -0.050083
result_sum : 1.118591, mean(result_sum) : 0.022372
benefit : 24

 End check_performance !

Test about test_set
End load_moodel !

End prediction !

len_ori : 180, len_pred : 180
======= difference ======= 
idx : 1, pred - ori : -0.005643
idx : 2, pred - ori : -0.013435
idx : 3, pred - ori : -0.000513
idx : 4, pred - ori : 0.011372
idx : 5, pred - ori : 0.018717
idx : 6, pred - ori : 0.021037
idx : 7, pred - ori : 0.018650
idx : 8, pred - ori : 0.018534
idx : 9, pred - ori : 0.015503
idx : 10, pred - ori : 0.016829
idx : 11, pred - ori : 0.013070
idx : 12, pred - ori : 0.019533
idx : 13, pred - ori : -0.002346
idx : 14, pred - ori : 0.006391
idx : 15, pred - ori : 0.014526
idx : 16, pred - ori : -0.000366
idx : 17, pred - ori : 0.009269
idx : 18, pred - ori : 0.006216
idx : 19, pred - ori : 0.004517
idx : 20, pred - ori : -0.018866
idx : 21, pred - ori : 0.008519
idx : 22, pred - ori : 0.019721
idx : 23, pred - ori : 0.022045
idx : 24, pred - ori : 0.032419
idx : 25, pred - ori : 0.027973
idx : 26, pred - ori : 0.031843
idx : 27, pred - ori : 0.021230
idx : 28, pred - ori : 0.020306
idx : 29, pred - ori : 0.021895
idx : 30, pred - ori : 0.023841
idx : 31, pred - ori : 0.028320
idx : 32, pred - ori : 0.050769
idx : 33, pred - ori : 0.083996
idx : 34, pred - ori : 0.117719
idx : 35, pred - ori : 0.085495
idx : 36, pred - ori : 0.069847
idx : 37, pred - ori : 0.047380
idx : 38, pred - ori : 0.020905
idx : 39, pred - ori : 0.012558
idx : 40, pred - ori : 0.024645
idx : 41, pred - ori : 0.053846
idx : 42, pred - ori : 0.053575
idx : 43, pred - ori : 0.050839
idx : 44, pred - ori : 0.015102
idx : 45, pred - ori : 0.012994
idx : 46, pred - ori : 0.014479
idx : 47, pred - ori : 0.002714
idx : 48, pred - ori : 0.026524
idx : 49, pred - ori : 0.036221
idx : 50, pred - ori : 0.017610
idx : 51, pred - ori : 0.000670
idx : 52, pred - ori : -0.020047
idx : 53, pred - ori : -0.015670
idx : 54, pred - ori : -0.021753
idx : 55, pred - ori : -0.035276
idx : 56, pred - ori : -0.040311
idx : 57, pred - ori : -0.001060
idx : 58, pred - ori : -0.022496
idx : 59, pred - ori : -0.026886
idx : 60, pred - ori : -0.007919
idx : 61, pred - ori : -0.000815
idx : 62, pred - ori : -0.015241
idx : 63, pred - ori : -0.003839
idx : 64, pred - ori : 0.000351
idx : 65, pred - ori : -0.003126
idx : 66, pred - ori : 0.003507
idx : 67, pred - ori : -0.023933
idx : 68, pred - ori : -0.053188
idx : 69, pred - ori : -0.033279
idx : 70, pred - ori : -0.037762
idx : 71, pred - ori : -0.015417
idx : 72, pred - ori : -0.026824
idx : 73, pred - ori : -0.007191
idx : 74, pred - ori : 0.010553
idx : 75, pred - ori : 0.017271
idx : 76, pred - ori : 0.010949
idx : 77, pred - ori : 0.018560
idx : 78, pred - ori : 0.024089
idx : 79, pred - ori : 0.018999
idx : 80, pred - ori : 0.030616
idx : 81, pred - ori : 0.049173
idx : 82, pred - ori : 0.050686
idx : 83, pred - ori : 0.028621
idx : 84, pred - ori : 0.006092
idx : 85, pred - ori : -0.029011
idx : 86, pred - ori : -0.033845
idx : 87, pred - ori : -0.031151
idx : 88, pred - ori : -0.035526
idx : 89, pred - ori : -0.038430
idx : 90, pred - ori : -0.047182
idx : 91, pred - ori : -0.061918
idx : 92, pred - ori : -0.150540
idx : 93, pred - ori : -0.148650
idx : 94, pred - ori : -0.141976
idx : 95, pred - ori : -0.137028
idx : 96, pred - ori : -0.111706
idx : 97, pred - ori : -0.135484
idx : 98, pred - ori : -0.110957
idx : 99, pred - ori : -0.087185
idx : 100, pred - ori : -0.104623
idx : 101, pred - ori : -0.091903
idx : 102, pred - ori : -0.071251
idx : 103, pred - ori : -0.099803
idx : 104, pred - ori : -0.189821
idx : 105, pred - ori : -0.213653
idx : 106, pred - ori : -0.247405
idx : 107, pred - ori : -0.273932
idx : 108, pred - ori : -0.229690
idx : 109, pred - ori : -0.275418
idx : 110, pred - ori : -0.217237
idx : 111, pred - ori : -0.190658
idx : 112, pred - ori : -0.194858
idx : 113, pred - ori : -0.190133
idx : 114, pred - ori : -0.180854
idx : 115, pred - ori : -0.196528
idx : 116, pred - ori : -0.179693
idx : 117, pred - ori : -0.145843
idx : 118, pred - ori : -0.101793
idx : 119, pred - ori : -0.135280
idx : 120, pred - ori : -0.154251
idx : 121, pred - ori : -0.125166
idx : 122, pred - ori : -0.130199
idx : 123, pred - ori : -0.157544
idx : 124, pred - ori : -0.238380
idx : 125, pred - ori : -0.286907
idx : 126, pred - ori : -0.290298
idx : 127, pred - ori : -0.324097
idx : 128, pred - ori : -0.354477
idx : 129, pred - ori : -0.287245
idx : 130, pred - ori : -0.229958
idx : 131, pred - ori : -0.261965
idx : 132, pred - ori : -0.223532
idx : 133, pred - ori : -0.181231
idx : 134, pred - ori : -0.204498
idx : 135, pred - ori : -0.207335
idx : 136, pred - ori : -0.204175
idx : 137, pred - ori : -0.214017
idx : 138, pred - ori : -0.179668
idx : 139, pred - ori : -0.248338
idx : 140, pred - ori : -0.181157
idx : 141, pred - ori : -0.172265
idx : 142, pred - ori : -0.110682
idx : 143, pred - ori : -0.103139
idx : 144, pred - ori : -0.131025
idx : 145, pred - ori : -0.190267
idx : 146, pred - ori : -0.195727
idx : 147, pred - ori : -0.145611
idx : 148, pred - ori : -0.176165
idx : 149, pred - ori : -0.150155
idx : 150, pred - ori : -0.154368
idx : 151, pred - ori : -0.161406
idx : 152, pred - ori : -0.229855
idx : 153, pred - ori : -0.237174
idx : 154, pred - ori : -0.209901
idx : 155, pred - ori : -0.165024
idx : 156, pred - ori : -0.239522
idx : 157, pred - ori : -0.275376
idx : 158, pred - ori : -0.294455
idx : 159, pred - ori : -0.265232
idx : 160, pred - ori : -0.399530
idx : 161, pred - ori : -0.316564
idx : 162, pred - ori : -0.338679
idx : 163, pred - ori : -0.358201
idx : 164, pred - ori : -0.292249
idx : 165, pred - ori : -0.258350
idx : 166, pred - ori : -0.201841
idx : 167, pred - ori : -0.205510
idx : 168, pred - ori : -0.163276
idx : 169, pred - ori : -0.206555
idx : 170, pred - ori : -0.242195
idx : 171, pred - ori : -0.205852
idx : 172, pred - ori : -0.251242
idx : 173, pred - ori : -0.248244
idx : 174, pred - ori : -0.268645
idx : 175, pred - ori : -0.223285
idx : 176, pred - ori : -0.220989
idx : 177, pred - ori : -0.186506
idx : 178, pred - ori : -0.168492
idx : 179, pred - ori : -0.163488
idx : 180, pred - ori : -0.188149
result_sum : 20.203424, mean(result_sum) : 0.112241
benefit : 122

 End check_performance !

Finish sk
Start hyundai
End load_stock_and_preprocessing !

IN make_train_test_set 
train_data X shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 20, 1)
train_data Y shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 1)
valid_data X shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 20, 1)
valid_data Y shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 1)
test_data X shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 20, 1)
test_data Y shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 1)

End make_train_test_set !

IN make_model, print model <tensorflow.python.keras.engine.sequential.Sequential object at 0x7fadca1383d0>
IN learning, print model <tensorflow.python.keras.engine.sequential.Sequential object at 0x7fadca1383d0>
train_data X shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 20, 1)
train_data Y shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 1)
valid_data X shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 20, 1)
valid_data Y shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 1)
Epoch 1/50

      1/Unknown - 1s 1s/step - loss: 0.0408 - mse: 0.0816
9/9 [==============================] - 2s 49ms/step - loss: 0.0380 - mse: 0.0761 - val_loss: 0.0050 - val_mse: 0.0100

Epoch 00001: val_loss improved from inf to 0.00498, saving model to ./model/models/005380/005380.ckpt
Epoch 2/50

1/9 [==>...........................] - ETA: 0s - loss: 0.0295 - mse: 0.0590
9/9 [==============================] - 0s 8ms/step - loss: 0.0256 - mse: 0.0513 - val_loss: 0.0023 - val_mse: 0.0047

Epoch 00002: val_loss improved from 0.00498 to 0.00234, saving model to ./model/models/005380/005380.ckpt
Epoch 3/50

1/9 [==>...........................] - ETA: 0s - loss: 0.0172 - mse: 0.0344
9/9 [==============================] - 0s 10ms/step - loss: 0.0149 - mse: 0.0298 - val_loss: 6.0044e-04 - val_mse: 0.0012

Epoch 00003: val_loss improved from 0.00234 to 0.00060, saving model to ./model/models/005380/005380.ckpt
Epoch 4/50

1/9 [==>...........................] - ETA: 0s - loss: 0.0082 - mse: 0.0163
9/9 [==============================] - 0s 9ms/step - loss: 0.0058 - mse: 0.0116 - val_loss: 6.5135e-04 - val_mse: 0.0013

Epoch 00004: val_loss did not improve from 0.00060
Epoch 5/50

1/9 [==>...........................] - ETA: 0s - loss: 0.0014 - mse: 0.0027
9/9 [==============================] - 0s 9ms/step - loss: 7.2175e-04 - mse: 0.0014 - val_loss: 0.0023 - val_mse: 0.0047

Epoch 00005: val_loss did not improve from 0.00060
Epoch 6/50

1/9 [==>...........................] - ETA: 0s - loss: 4.3955e-04 - mse: 8.7910e-04
9/9 [==============================] - 0s 9ms/step - loss: 4.9240e-04 - mse: 9.8480e-04 - val_loss: 0.0018 - val_mse: 0.0037

Epoch 00006: val_loss did not improve from 0.00060
Epoch 7/50

1/9 [==>...........................] - ETA: 0s - loss: 2.1363e-04 - mse: 4.2725e-04
9/9 [==============================] - 0s 9ms/step - loss: 2.1975e-04 - mse: 4.3951e-04 - val_loss: 0.0012 - val_mse: 0.0024

Epoch 00007: val_loss did not improve from 0.00060
Epoch 8/50

1/9 [==>...........................] - ETA: 0s - loss: 3.1218e-04 - mse: 6.2436e-04
9/9 [==============================] - 0s 8ms/step - loss: 2.4076e-04 - mse: 4.8153e-04 - val_loss: 0.0017 - val_mse: 0.0033

Epoch 00008: val_loss did not improve from 0.00060
Epoch 9/50

1/9 [==>...........................] - ETA: 0s - loss: 2.2192e-04 - mse: 4.4384e-04
9/9 [==============================] - 0s 8ms/step - loss: 2.0562e-04 - mse: 4.1124e-04 - val_loss: 0.0017 - val_mse: 0.0033

Epoch 00009: val_loss did not improve from 0.00060
Epoch 10/50

1/9 [==>...........................] - ETA: 0s - loss: 1.7932e-04 - mse: 3.5865e-04
9/9 [==============================] - 0s 8ms/step - loss: 1.9225e-04 - mse: 3.8449e-04 - val_loss: 0.0015 - val_mse: 0.0030

Epoch 00010: val_loss did not improve from 0.00060
Epoch 11/50

1/9 [==>...........................] - ETA: 0s - loss: 1.6846e-04 - mse: 3.3693e-04
9/9 [==============================] - 0s 8ms/step - loss: 2.0143e-04 - mse: 4.0286e-04 - val_loss: 0.0016 - val_mse: 0.0032

Epoch 00011: val_loss did not improve from 0.00060
Epoch 12/50

1/9 [==>...........................] - ETA: 0s - loss: 1.8411e-04 - mse: 3.6823e-04
9/9 [==============================] - 0s 9ms/step - loss: 1.9535e-04 - mse: 3.9070e-04 - val_loss: 0.0016 - val_mse: 0.0032

Epoch 00012: val_loss did not improve from 0.00060
Epoch 13/50

1/9 [==>...........................] - ETA: 0s - loss: 1.9590e-04 - mse: 3.9180e-04
9/9 [==============================] - 0s 8ms/step - loss: 1.9531e-04 - mse: 3.9061e-04 - val_loss: 0.0014 - val_mse: 0.0029

Epoch 00013: val_loss did not improve from 0.00060
End learning !
End make_model !

005380 Start check_bias_variance !
Test about valid_set
End load_moodel !

End prediction !

len_ori : 50, len_pred : 50
======= difference ======= 
idx : 1, pred - ori : 0.082740
idx : 2, pred - ori : 0.047412
idx : 3, pred - ori : -0.004996
idx : 4, pred - ori : -0.005815
idx : 5, pred - ori : -0.009901
idx : 6, pred - ori : -0.001588
idx : 7, pred - ori : -0.015902
idx : 8, pred - ori : 0.002432
idx : 9, pred - ori : -0.002092
idx : 10, pred - ori : 0.000043
idx : 11, pred - ori : -0.011473
idx : 12, pred - ori : -0.018581
idx : 13, pred - ori : -0.015059
idx : 14, pred - ori : -0.048892
idx : 15, pred - ori : -0.059368
idx : 16, pred - ori : -0.046206
idx : 17, pred - ori : -0.054090
idx : 18, pred - ori : -0.046651
idx : 19, pred - ori : -0.050973
idx : 20, pred - ori : -0.034542
idx : 21, pred - ori : -0.012677
idx : 22, pred - ori : -0.008304
idx : 23, pred - ori : -0.008129
idx : 24, pred - ori : 0.002190
idx : 25, pred - ori : -0.006716
idx : 26, pred - ori : -0.015895
idx : 27, pred - ori : -0.018280
idx : 28, pred - ori : -0.008007
idx : 29, pred - ori : -0.016687
idx : 30, pred - ori : -0.013913
idx : 31, pred - ori : -0.023338
idx : 32, pred - ori : -0.019289
idx : 33, pred - ori : -0.009986
idx : 34, pred - ori : -0.016187
idx : 35, pred - ori : -0.012420
idx : 36, pred - ori : -0.012644
idx : 37, pred - ori : -0.011050
idx : 38, pred - ori : -0.047050
idx : 39, pred - ori : -0.037240
idx : 40, pred - ori : -0.035092
idx : 41, pred - ori : -0.020739
idx : 42, pred - ori : -0.027427
idx : 43, pred - ori : -0.036223
idx : 44, pred - ori : -0.036981
idx : 45, pred - ori : -0.031727
idx : 46, pred - ori : -0.035027
idx : 47, pred - ori : -0.044347
idx : 48, pred - ori : -0.055801
idx : 49, pred - ori : -0.084058
idx : 50, pred - ori : -0.081385
result_sum : 1.347564, mean(result_sum) : 0.026951
benefit : 45

 End check_performance !

Test about test_set
End load_moodel !

End prediction !

len_ori : 180, len_pred : 180
======= difference ======= 
idx : 1, pred - ori : -0.034551
idx : 2, pred - ori : -0.046211
idx : 3, pred - ori : -0.034554
idx : 4, pred - ori : -0.036327
idx : 5, pred - ori : -0.036503
idx : 6, pred - ori : -0.029949
idx : 7, pred - ori : -0.046156
idx : 8, pred - ori : -0.045925
idx : 9, pred - ori : -0.082441
idx : 10, pred - ori : -0.085710
idx : 11, pred - ori : -0.119711
idx : 12, pred - ori : -0.135815
idx : 13, pred - ori : -0.130118
idx : 14, pred - ori : -0.110129
idx : 15, pred - ori : -0.135872
idx : 16, pred - ori : -0.122066
idx : 17, pred - ori : -0.123307
idx : 18, pred - ori : -0.118160
idx : 19, pred - ori : -0.125313
idx : 20, pred - ori : -0.135494
idx : 21, pred - ori : -0.127854
idx : 22, pred - ori : -0.127991
idx : 23, pred - ori : -0.153247
idx : 24, pred - ori : -0.157939
idx : 25, pred - ori : -0.206830
idx : 26, pred - ori : -0.214785
idx : 27, pred - ori : -0.322734
idx : 28, pred - ori : -0.358718
idx : 29, pred - ori : -0.310939
idx : 30, pred - ori : -0.289890
idx : 31, pred - ori : -0.265981
idx : 32, pred - ori : -0.214717
idx : 33, pred - ori : -0.244193
idx : 34, pred - ori : -0.195165
idx : 35, pred - ori : -0.199085
idx : 36, pred - ori : -0.227195
idx : 37, pred - ori : -0.248480
idx : 38, pred - ori : -0.254466
idx : 39, pred - ori : -0.232207
idx : 40, pred - ori : -0.272374
idx : 41, pred - ori : -0.292193
idx : 42, pred - ori : -0.305700
idx : 43, pred - ori : -0.281397
idx : 44, pred - ori : -0.279851
idx : 45, pred - ori : -0.257022
idx : 46, pred - ori : -0.242767
idx : 47, pred - ori : -0.232507
idx : 48, pred - ori : -0.230668
idx : 49, pred - ori : -0.239333
idx : 50, pred - ori : -0.252648
idx : 51, pred - ori : -0.295035
idx : 52, pred - ori : -0.288583
idx : 53, pred - ori : -0.308340
idx : 54, pred - ori : -0.307900
idx : 55, pred - ori : -0.289505
idx : 56, pred - ori : -0.306816
idx : 57, pred - ori : -0.277142
idx : 58, pred - ori : -0.275579
idx : 59, pred - ori : -0.235412
idx : 60, pred - ori : -0.228665
idx : 61, pred - ori : -0.258246
idx : 62, pred - ori : -0.274658
idx : 63, pred - ori : -0.317285
idx : 64, pred - ori : -0.293370
idx : 65, pred - ori : -0.293687
idx : 66, pred - ori : -0.279697
idx : 67, pred - ori : -0.275978
idx : 68, pred - ori : -0.270684
idx : 69, pred - ori : -0.265652
idx : 70, pred - ori : -0.256146
idx : 71, pred - ori : -0.237111
idx : 72, pred - ori : -0.218947
idx : 73, pred - ori : -0.219076
idx : 74, pred - ori : -0.212180
idx : 75, pred - ori : -0.200434
idx : 76, pred - ori : -0.226155
idx : 77, pred - ori : -0.251165
idx : 78, pred - ori : -0.257160
idx : 79, pred - ori : -0.262137
idx : 80, pred - ori : -0.244070
idx : 81, pred - ori : -0.216386
idx : 82, pred - ori : -0.247148
idx : 83, pred - ori : -0.248014
idx : 84, pred - ori : -0.253267
idx : 85, pred - ori : -0.270678
idx : 86, pred - ori : -0.247471
idx : 87, pred - ori : -0.256813
idx : 88, pred - ori : -0.261466
idx : 89, pred - ori : -0.270715
idx : 90, pred - ori : -0.262431
idx : 91, pred - ori : -0.278838
idx : 92, pred - ori : -0.285098
idx : 93, pred - ori : -0.300695
idx : 94, pred - ori : -0.283600
idx : 95, pred - ori : -0.283954
idx : 96, pred - ori : -0.267528
idx : 97, pred - ori : -0.276537
idx : 98, pred - ori : -0.286045
idx : 99, pred - ori : -0.277731
idx : 100, pred - ori : -0.274541
idx : 101, pred - ori : -0.283938
idx : 102, pred - ori : -0.285714
idx : 103, pred - ori : -0.294834
idx : 104, pred - ori : -0.288795
idx : 105, pred - ori : -0.357107
idx : 106, pred - ori : -0.354246
idx : 107, pred - ori : -0.334957
idx : 108, pred - ori : -0.296684
idx : 109, pred - ori : -0.319390
idx : 110, pred - ori : -0.318290
idx : 111, pred - ori : -0.309517
idx : 112, pred - ori : -0.303811
idx : 113, pred - ori : -0.300779
idx : 114, pred - ori : -0.308149
idx : 115, pred - ori : -0.310445
idx : 116, pred - ori : -0.302594
idx : 117, pred - ori : -0.292406
idx : 118, pred - ori : -0.277728
idx : 119, pred - ori : -0.283625
idx : 120, pred - ori : -0.294718
idx : 121, pred - ori : -0.307808
idx : 122, pred - ori : -0.312782
idx : 123, pred - ori : -0.319591
idx : 124, pred - ori : -0.395495
idx : 125, pred - ori : -0.402020
idx : 126, pred - ori : -0.364634
idx : 127, pred - ori : -0.375398
idx : 128, pred - ori : -0.570230
idx : 129, pred - ori : -0.667956
idx : 130, pred - ori : -0.621375
idx : 131, pred - ori : -0.596616
idx : 132, pred - ori : -0.540281
idx : 133, pred - ori : -0.479411
idx : 134, pred - ori : -0.481501
idx : 135, pred - ori : -0.581774
idx : 136, pred - ori : -0.565641
idx : 137, pred - ori : -0.587622
idx : 138, pred - ori : -0.544976
idx : 139, pred - ori : -0.554103
idx : 140, pred - ori : -0.509537
idx : 141, pred - ori : -0.477812
idx : 142, pred - ori : -0.444124
idx : 143, pred - ori : -0.398705
idx : 144, pred - ori : -0.449917
idx : 145, pred - ori : -0.463064
idx : 146, pred - ori : -0.489060
idx : 147, pred - ori : -0.504158
idx : 148, pred - ori : -0.507056
idx : 149, pred - ori : -0.429010
idx : 150, pred - ori : -0.442261
idx : 151, pred - ori : -0.487036
idx : 152, pred - ori : -0.500176
idx : 153, pred - ori : -0.500483
idx : 154, pred - ori : -0.479212
idx : 155, pred - ori : -0.438568
idx : 156, pred - ori : -0.472190
idx : 157, pred - ori : -0.471115
idx : 158, pred - ori : -0.486703
idx : 159, pred - ori : -0.440021
idx : 160, pred - ori : -0.489840
idx : 161, pred - ori : -0.450712
idx : 162, pred - ori : -0.460539
idx : 163, pred - ori : -0.467001
idx : 164, pred - ori : -0.441554
idx : 165, pred - ori : -0.442964
idx : 166, pred - ori : -0.421695
idx : 167, pred - ori : -0.428275
idx : 168, pred - ori : -0.410613
idx : 169, pred - ori : -0.417425
idx : 170, pred - ori : -0.439375
idx : 171, pred - ori : -0.437621
idx : 172, pred - ori : -0.448177
idx : 173, pred - ori : -0.438278
idx : 174, pred - ori : -0.448063
idx : 175, pred - ori : -0.425947
idx : 176, pred - ori : -0.423723
idx : 177, pred - ori : -0.412553
idx : 178, pred - ori : -0.386364
idx : 179, pred - ori : -0.373961
idx : 180, pred - ori : -0.364318
result_sum : 56.055126, mean(result_sum) : 0.311417
benefit : 180

 End check_performance !

Finish hyundai
Start lg
End load_stock_and_preprocessing !

IN make_train_test_set 
train_data X shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 20, 1)
train_data Y shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 1)
valid_data X shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 20, 1)
valid_data Y shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 1)
test_data X shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 20, 1)
test_data Y shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 1)

End make_train_test_set !

IN make_model, print model <tensorflow.python.keras.engine.sequential.Sequential object at 0x7fadc049bb90>
IN learning, print model <tensorflow.python.keras.engine.sequential.Sequential object at 0x7fadc049bb90>
train_data X shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 20, 1)
train_data Y shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 1)
valid_data X shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 20, 1)
valid_data Y shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 1)
Epoch 1/50

      1/Unknown - 2s 2s/step - loss: 0.0107 - mse: 0.0214
9/9 [==============================] - 2s 49ms/step - loss: 0.0096 - mse: 0.0193 - val_loss: 0.0078 - val_mse: 0.0156

Epoch 00001: val_loss improved from inf to 0.00780, saving model to ./model/models/051910/051910.ckpt
Epoch 2/50

1/9 [==>...........................] - ETA: 0s - loss: 0.0064 - mse: 0.0129
9/9 [==============================] - 0s 9ms/step - loss: 0.0060 - mse: 0.0120 - val_loss: 0.0049 - val_mse: 0.0097

Epoch 00002: val_loss improved from 0.00780 to 0.00486, saving model to ./model/models/051910/051910.ckpt
Epoch 3/50

1/9 [==>...........................] - ETA: 0s - loss: 0.0049 - mse: 0.0098
9/9 [==============================] - 0s 10ms/step - loss: 0.0037 - mse: 0.0074 - val_loss: 0.0025 - val_mse: 0.0050

Epoch 00003: val_loss improved from 0.00486 to 0.00249, saving model to ./model/models/051910/051910.ckpt
Epoch 4/50

1/9 [==>...........................] - ETA: 0s - loss: 0.0021 - mse: 0.0041
9/9 [==============================] - 0s 8ms/step - loss: 0.0016 - mse: 0.0031 - val_loss: 9.8396e-04 - val_mse: 0.0020

Epoch 00004: val_loss improved from 0.00249 to 0.00098, saving model to ./model/models/051910/051910.ckpt
Epoch 5/50

1/9 [==>...........................] - ETA: 0s - loss: 5.7863e-04 - mse: 0.0012
9/9 [==============================] - 0s 10ms/step - loss: 5.0918e-04 - mse: 0.0010 - val_loss: 5.6943e-04 - val_mse: 0.0011

Epoch 00005: val_loss improved from 0.00098 to 0.00057, saving model to ./model/models/051910/051910.ckpt
Epoch 6/50

1/9 [==>...........................] - ETA: 0s - loss: 3.7724e-04 - mse: 7.5449e-04
9/9 [==============================] - 0s 8ms/step - loss: 4.1310e-04 - mse: 8.2620e-04 - val_loss: 5.5452e-04 - val_mse: 0.0011

Epoch 00006: val_loss improved from 0.00057 to 0.00055, saving model to ./model/models/051910/051910.ckpt
Epoch 7/50

1/9 [==>...........................] - ETA: 0s - loss: 2.6178e-04 - mse: 5.2355e-04
9/9 [==============================] - 0s 8ms/step - loss: 3.9605e-04 - mse: 7.9210e-04 - val_loss: 5.6573e-04 - val_mse: 0.0011

Epoch 00007: val_loss did not improve from 0.00055
Epoch 8/50

1/9 [==>...........................] - ETA: 0s - loss: 2.9099e-04 - mse: 5.8197e-04
9/9 [==============================] - 0s 8ms/step - loss: 3.4533e-04 - mse: 6.9066e-04 - val_loss: 6.0406e-04 - val_mse: 0.0012

Epoch 00008: val_loss did not improve from 0.00055
Epoch 9/50

1/9 [==>...........................] - ETA: 0s - loss: 4.1878e-04 - mse: 8.3757e-04
9/9 [==============================] - 0s 9ms/step - loss: 3.5177e-04 - mse: 7.0354e-04 - val_loss: 5.5372e-04 - val_mse: 0.0011

Epoch 00009: val_loss improved from 0.00055 to 0.00055, saving model to ./model/models/051910/051910.ckpt
Epoch 10/50

1/9 [==>...........................] - ETA: 0s - loss: 3.3690e-04 - mse: 6.7380e-04
9/9 [==============================] - 0s 9ms/step - loss: 3.3222e-04 - mse: 6.6443e-04 - val_loss: 4.6418e-04 - val_mse: 9.2835e-04

Epoch 00010: val_loss improved from 0.00055 to 0.00046, saving model to ./model/models/051910/051910.ckpt
Epoch 11/50

1/9 [==>...........................] - ETA: 0s - loss: 2.9088e-04 - mse: 5.8177e-04
9/9 [==============================] - 0s 9ms/step - loss: 2.7382e-04 - mse: 5.4763e-04 - val_loss: 5.1007e-04 - val_mse: 0.0010

Epoch 00011: val_loss did not improve from 0.00046
Epoch 12/50

1/9 [==>...........................] - ETA: 0s - loss: 3.2260e-04 - mse: 6.4520e-04
9/9 [==============================] - 0s 9ms/step - loss: 2.7714e-04 - mse: 5.5429e-04 - val_loss: 4.2681e-04 - val_mse: 8.5363e-04

Epoch 00012: val_loss improved from 0.00046 to 0.00043, saving model to ./model/models/051910/051910.ckpt
Epoch 13/50

1/9 [==>...........................] - ETA: 0s - loss: 2.8389e-04 - mse: 5.6778e-04
9/9 [==============================] - 0s 9ms/step - loss: 2.3510e-04 - mse: 4.7020e-04 - val_loss: 4.4612e-04 - val_mse: 8.9224e-04

Epoch 00013: val_loss did not improve from 0.00043
Epoch 14/50

1/9 [==>...........................] - ETA: 0s - loss: 3.3150e-04 - mse: 6.6300e-04
9/9 [==============================] - 0s 10ms/step - loss: 2.4451e-04 - mse: 4.8902e-04 - val_loss: 3.9661e-04 - val_mse: 7.9322e-04

Epoch 00014: val_loss improved from 0.00043 to 0.00040, saving model to ./model/models/051910/051910.ckpt
Epoch 15/50

1/9 [==>...........................] - ETA: 0s - loss: 1.3669e-04 - mse: 2.7337e-04
9/9 [==============================] - 0s 8ms/step - loss: 1.8431e-04 - mse: 3.6861e-04 - val_loss: 4.1306e-04 - val_mse: 8.2611e-04

Epoch 00015: val_loss did not improve from 0.00040
Epoch 16/50

1/9 [==>...........................] - ETA: 0s - loss: 1.7408e-04 - mse: 3.4816e-04
9/9 [==============================] - 0s 9ms/step - loss: 1.7741e-04 - mse: 3.5482e-04 - val_loss: 3.6296e-04 - val_mse: 7.2592e-04

Epoch 00016: val_loss improved from 0.00040 to 0.00036, saving model to ./model/models/051910/051910.ckpt
Epoch 17/50

1/9 [==>...........................] - ETA: 0s - loss: 1.7603e-04 - mse: 3.5206e-04
9/9 [==============================] - 0s 9ms/step - loss: 1.6582e-04 - mse: 3.3163e-04 - val_loss: 4.0457e-04 - val_mse: 8.0913e-04

Epoch 00017: val_loss did not improve from 0.00036
Epoch 18/50

1/9 [==>...........................] - ETA: 0s - loss: 1.4617e-04 - mse: 2.9233e-04
9/9 [==============================] - 0s 9ms/step - loss: 1.5078e-04 - mse: 3.0157e-04 - val_loss: 3.5957e-04 - val_mse: 7.1914e-04

Epoch 00018: val_loss improved from 0.00036 to 0.00036, saving model to ./model/models/051910/051910.ckpt
Epoch 19/50

1/9 [==>...........................] - ETA: 0s - loss: 8.3615e-05 - mse: 1.6723e-04
9/9 [==============================] - 0s 9ms/step - loss: 1.4619e-04 - mse: 2.9238e-04 - val_loss: 3.8725e-04 - val_mse: 7.7450e-04

Epoch 00019: val_loss did not improve from 0.00036
Epoch 20/50

1/9 [==>...........................] - ETA: 0s - loss: 1.0471e-04 - mse: 2.0942e-04
9/9 [==============================] - 0s 9ms/step - loss: 1.3103e-04 - mse: 2.6205e-04 - val_loss: 3.2430e-04 - val_mse: 6.4861e-04

Epoch 00020: val_loss improved from 0.00036 to 0.00032, saving model to ./model/models/051910/051910.ckpt
Epoch 21/50

1/9 [==>...........................] - ETA: 0s - loss: 1.8429e-04 - mse: 3.6858e-04
9/9 [==============================] - 0s 10ms/step - loss: 1.6332e-04 - mse: 3.2664e-04 - val_loss: 4.1752e-04 - val_mse: 8.3504e-04

Epoch 00021: val_loss did not improve from 0.00032
Epoch 22/50

1/9 [==>...........................] - ETA: 0s - loss: 1.7118e-04 - mse: 3.4236e-04
9/9 [==============================] - 0s 9ms/step - loss: 1.5283e-04 - mse: 3.0567e-04 - val_loss: 3.4696e-04 - val_mse: 6.9392e-04

Epoch 00022: val_loss did not improve from 0.00032
Epoch 23/50

1/9 [==>...........................] - ETA: 0s - loss: 1.3399e-04 - mse: 2.6797e-04
9/9 [==============================] - 0s 9ms/step - loss: 1.2583e-04 - mse: 2.5166e-04 - val_loss: 3.7008e-04 - val_mse: 7.4017e-04

Epoch 00023: val_loss did not improve from 0.00032
Epoch 24/50

1/9 [==>...........................] - ETA: 0s - loss: 6.7921e-05 - mse: 1.3584e-04
9/9 [==============================] - 0s 9ms/step - loss: 1.1456e-04 - mse: 2.2911e-04 - val_loss: 3.5114e-04 - val_mse: 7.0227e-04

Epoch 00024: val_loss did not improve from 0.00032
Epoch 25/50

1/9 [==>...........................] - ETA: 0s - loss: 1.4959e-04 - mse: 2.9918e-04
9/9 [==============================] - 0s 9ms/step - loss: 1.3286e-04 - mse: 2.6572e-04 - val_loss: 3.5045e-04 - val_mse: 7.0090e-04

Epoch 00025: val_loss did not improve from 0.00032
Epoch 26/50

1/9 [==>...........................] - ETA: 0s - loss: 1.2334e-04 - mse: 2.4668e-04
9/9 [==============================] - 0s 10ms/step - loss: 1.2539e-04 - mse: 2.5078e-04 - val_loss: 3.4068e-04 - val_mse: 6.8136e-04

Epoch 00026: val_loss did not improve from 0.00032
Epoch 27/50

1/9 [==>...........................] - ETA: 0s - loss: 8.6413e-05 - mse: 1.7283e-04
9/9 [==============================] - 0s 10ms/step - loss: 1.1948e-04 - mse: 2.3897e-04 - val_loss: 3.4567e-04 - val_mse: 6.9134e-04

Epoch 00027: val_loss did not improve from 0.00032
Epoch 28/50

1/9 [==>...........................] - ETA: 0s - loss: 9.0768e-05 - mse: 1.8154e-04
9/9 [==============================] - 0s 9ms/step - loss: 1.1129e-04 - mse: 2.2258e-04 - val_loss: 3.2398e-04 - val_mse: 6.4796e-04

Epoch 00028: val_loss improved from 0.00032 to 0.00032, saving model to ./model/models/051910/051910.ckpt
Epoch 29/50

1/9 [==>...........................] - ETA: 0s - loss: 5.9892e-05 - mse: 1.1978e-04
9/9 [==============================] - 0s 9ms/step - loss: 1.1157e-04 - mse: 2.2314e-04 - val_loss: 3.6433e-04 - val_mse: 7.2865e-04

Epoch 00029: val_loss did not improve from 0.00032
Epoch 30/50

1/9 [==>...........................] - ETA: 0s - loss: 8.2922e-05 - mse: 1.6584e-04
9/9 [==============================] - 0s 8ms/step - loss: 1.1233e-04 - mse: 2.2466e-04 - val_loss: 3.0098e-04 - val_mse: 6.0195e-04

Epoch 00030: val_loss improved from 0.00032 to 0.00030, saving model to ./model/models/051910/051910.ckpt
Epoch 31/50

1/9 [==>...........................] - ETA: 0s - loss: 1.5320e-04 - mse: 3.0641e-04
9/9 [==============================] - 0s 8ms/step - loss: 1.2757e-04 - mse: 2.5514e-04 - val_loss: 3.9065e-04 - val_mse: 7.8130e-04

Epoch 00031: val_loss did not improve from 0.00030
Epoch 32/50

1/9 [==>...........................] - ETA: 0s - loss: 1.2559e-04 - mse: 2.5118e-04
9/9 [==============================] - 0s 9ms/step - loss: 1.3063e-04 - mse: 2.6126e-04 - val_loss: 2.7829e-04 - val_mse: 5.5657e-04

Epoch 00032: val_loss improved from 0.00030 to 0.00028, saving model to ./model/models/051910/051910.ckpt
Epoch 33/50

1/9 [==>...........................] - ETA: 0s - loss: 8.4317e-05 - mse: 1.6863e-04
9/9 [==============================] - 0s 9ms/step - loss: 1.1464e-04 - mse: 2.2929e-04 - val_loss: 3.5738e-04 - val_mse: 7.1476e-04

Epoch 00033: val_loss did not improve from 0.00028
Epoch 34/50

1/9 [==>...........................] - ETA: 0s - loss: 1.2018e-04 - mse: 2.4035e-04
9/9 [==============================] - 0s 9ms/step - loss: 1.1387e-04 - mse: 2.2774e-04 - val_loss: 2.8817e-04 - val_mse: 5.7635e-04

Epoch 00034: val_loss did not improve from 0.00028
Epoch 35/50

1/9 [==>...........................] - ETA: 0s - loss: 1.1974e-04 - mse: 2.3948e-04
9/9 [==============================] - 0s 9ms/step - loss: 1.1234e-04 - mse: 2.2467e-04 - val_loss: 3.2736e-04 - val_mse: 6.5473e-04

Epoch 00035: val_loss did not improve from 0.00028
Epoch 36/50

1/9 [==>...........................] - ETA: 0s - loss: 1.4776e-04 - mse: 2.9552e-04
9/9 [==============================] - 0s 8ms/step - loss: 1.1875e-04 - mse: 2.3750e-04 - val_loss: 3.1549e-04 - val_mse: 6.3099e-04

Epoch 00036: val_loss did not improve from 0.00028
Epoch 37/50

1/9 [==>...........................] - ETA: 0s - loss: 1.5143e-04 - mse: 3.0287e-04
9/9 [==============================] - 0s 9ms/step - loss: 1.1195e-04 - mse: 2.2390e-04 - val_loss: 2.9269e-04 - val_mse: 5.8539e-04

Epoch 00037: val_loss did not improve from 0.00028
Epoch 38/50

1/9 [==>...........................] - ETA: 0s - loss: 1.1749e-04 - mse: 2.3498e-04
9/9 [==============================] - 0s 9ms/step - loss: 1.0704e-04 - mse: 2.1408e-04 - val_loss: 2.9877e-04 - val_mse: 5.9754e-04

Epoch 00038: val_loss did not improve from 0.00028
Epoch 39/50

1/9 [==>...........................] - ETA: 0s - loss: 8.5193e-05 - mse: 1.7039e-04
9/9 [==============================] - 0s 9ms/step - loss: 1.0426e-04 - mse: 2.0852e-04 - val_loss: 2.9311e-04 - val_mse: 5.8622e-04

Epoch 00039: val_loss did not improve from 0.00028
Epoch 40/50

1/9 [==>...........................] - ETA: 0s - loss: 1.0391e-04 - mse: 2.0782e-04
9/9 [==============================] - 0s 9ms/step - loss: 1.0772e-04 - mse: 2.1544e-04 - val_loss: 2.9259e-04 - val_mse: 5.8519e-04

Epoch 00040: val_loss did not improve from 0.00028
Epoch 41/50

1/9 [==>...........................] - ETA: 0s - loss: 1.0457e-04 - mse: 2.0914e-04
9/9 [==============================] - 0s 9ms/step - loss: 9.9965e-05 - mse: 1.9993e-04 - val_loss: 2.8011e-04 - val_mse: 5.6022e-04

Epoch 00041: val_loss did not improve from 0.00028
Epoch 42/50

1/9 [==>...........................] - ETA: 0s - loss: 1.0335e-04 - mse: 2.0670e-04
9/9 [==============================] - 0s 9ms/step - loss: 1.0599e-04 - mse: 2.1198e-04 - val_loss: 2.8184e-04 - val_mse: 5.6369e-04

Epoch 00042: val_loss did not improve from 0.00028
End learning !
End make_model !

051910 Start check_bias_variance !
Test about valid_set
End load_moodel !

End prediction !

len_ori : 50, len_pred : 50
======= difference ======= 
idx : 1, pred - ori : 0.069285
idx : 2, pred - ori : 0.030995
idx : 3, pred - ori : -0.004653
idx : 4, pred - ori : 0.001417
idx : 5, pred - ori : -0.005782
idx : 6, pred - ori : -0.005129
idx : 7, pred - ori : -0.005540
idx : 8, pred - ori : 0.012670
idx : 9, pred - ori : 0.014903
idx : 10, pred - ori : 0.015896
idx : 11, pred - ori : 0.008695
idx : 12, pred - ori : -0.007031
idx : 13, pred - ori : -0.010913
idx : 14, pred - ori : -0.023458
idx : 15, pred - ori : -0.019672
idx : 16, pred - ori : -0.004331
idx : 17, pred - ori : -0.015722
idx : 18, pred - ori : -0.032567
idx : 19, pred - ori : -0.051970
idx : 20, pred - ori : -0.032497
idx : 21, pred - ori : -0.029821
idx : 22, pred - ori : -0.024697
idx : 23, pred - ori : -0.024957
idx : 24, pred - ori : -0.009599
idx : 25, pred - ori : -0.005182
idx : 26, pred - ori : -0.013232
idx : 27, pred - ori : -0.027112
idx : 28, pred - ori : -0.002297
idx : 29, pred - ori : -0.001061
idx : 30, pred - ori : 0.009562
idx : 31, pred - ori : 0.013333
idx : 32, pred - ori : 0.020605
idx : 33, pred - ori : 0.030028
idx : 34, pred - ori : 0.009676
idx : 35, pred - ori : 0.017079
idx : 36, pred - ori : 0.012499
idx : 37, pred - ori : 0.000358
idx : 38, pred - ori : -0.003916
idx : 39, pred - ori : -0.010789
idx : 40, pred - ori : -0.028727
idx : 41, pred - ori : -0.025043
idx : 42, pred - ori : -0.036839
idx : 43, pred - ori : -0.062594
idx : 44, pred - ori : -0.031031
idx : 45, pred - ori : -0.015153
idx : 46, pred - ori : -0.012288
idx : 47, pred - ori : -0.013149
idx : 48, pred - ori : -0.009149
idx : 49, pred - ori : -0.014074
idx : 50, pred - ori : -0.033183
result_sum : 0.920159, mean(result_sum) : 0.018403
benefit : 35

 End check_performance !

Test about test_set
End load_moodel !

End prediction !

len_ori : 180, len_pred : 180
======= difference ======= 
idx : 1, pred - ori : -0.063457
idx : 2, pred - ori : -0.065108
idx : 3, pred - ori : -0.072598
idx : 4, pred - ori : -0.066858
idx : 5, pred - ori : -0.097582
idx : 6, pred - ori : -0.081509
idx : 7, pred - ori : -0.101229
idx : 8, pred - ori : -0.080867
idx : 9, pred - ori : -0.090396
idx : 10, pred - ori : -0.060857
idx : 11, pred - ori : -0.050894
idx : 12, pred - ori : -0.044705
idx : 13, pred - ori : -0.071011
idx : 14, pred - ori : -0.066256
idx : 15, pred - ori : -0.072768
idx : 16, pred - ori : -0.052122
idx : 17, pred - ori : -0.053641
idx : 18, pred - ori : -0.067910
idx : 19, pred - ori : -0.066744
idx : 20, pred - ori : -0.070565
idx : 21, pred - ori : -0.117774
idx : 22, pred - ori : -0.198244
idx : 23, pred - ori : -0.198172
idx : 24, pred - ori : -0.222719
idx : 25, pred - ori : -0.221790
idx : 26, pred - ori : -0.290525
idx : 27, pred - ori : -0.240517
idx : 28, pred - ori : -0.273919
idx : 29, pred - ori : -0.236820
idx : 30, pred - ori : -0.219246
idx : 31, pred - ori : -0.162552
idx : 32, pred - ori : -0.144730
idx : 33, pred - ori : -0.133957
idx : 34, pred - ori : -0.114649
idx : 35, pred - ori : -0.157469
idx : 36, pred - ori : -0.161972
idx : 37, pred - ori : -0.175809
idx : 38, pred - ori : -0.229574
idx : 39, pred - ori : -0.230833
idx : 40, pred - ori : -0.221214
idx : 41, pred - ori : -0.191653
idx : 42, pred - ori : -0.191474
idx : 43, pred - ori : -0.187181
idx : 44, pred - ori : -0.218221
idx : 45, pred - ori : -0.183879
idx : 46, pred - ori : -0.153999
idx : 47, pred - ori : -0.140726
idx : 48, pred - ori : -0.130343
idx : 49, pred - ori : -0.151708
idx : 50, pred - ori : -0.144747
idx : 51, pred - ori : -0.156551
idx : 52, pred - ori : -0.175857
idx : 53, pred - ori : -0.127273
idx : 54, pred - ori : -0.077264
idx : 55, pred - ori : -0.108874
idx : 56, pred - ori : -0.065543
idx : 57, pred - ori : -0.089054
idx : 58, pred - ori : -0.084726
idx : 59, pred - ori : -0.067685
idx : 60, pred - ori : -0.094732
idx : 61, pred - ori : -0.098741
idx : 62, pred - ori : -0.138197
idx : 63, pred - ori : -0.145759
idx : 64, pred - ori : -0.164300
idx : 65, pred - ori : -0.169379
idx : 66, pred - ori : -0.181039
idx : 67, pred - ori : -0.151510
idx : 68, pred - ori : -0.113659
idx : 69, pred - ori : -0.093277
idx : 70, pred - ori : -0.106669
idx : 71, pred - ori : -0.113299
idx : 72, pred - ori : -0.084693
idx : 73, pred - ori : -0.096031
idx : 74, pred - ori : -0.093935
idx : 75, pred - ori : -0.124701
idx : 76, pred - ori : -0.139750
idx : 77, pred - ori : -0.134503
idx : 78, pred - ori : -0.116118
idx : 79, pred - ori : -0.128438
idx : 80, pred - ori : -0.138953
idx : 81, pred - ori : -0.087872
idx : 82, pred - ori : -0.104822
idx : 83, pred - ori : -0.147457
idx : 84, pred - ori : -0.139248
idx : 85, pred - ori : -0.172317
idx : 86, pred - ori : -0.222778
idx : 87, pred - ori : -0.233046
idx : 88, pred - ori : -0.184303
idx : 89, pred - ori : -0.165360
idx : 90, pred - ori : -0.160327
idx : 91, pred - ori : -0.173692
idx : 92, pred - ori : -0.136220
idx : 93, pred - ori : -0.147568
idx : 94, pred - ori : -0.175911
idx : 95, pred - ori : -0.189340
idx : 96, pred - ori : -0.190488
idx : 97, pred - ori : -0.217446
idx : 98, pred - ori : -0.276135
idx : 99, pred - ori : -0.253577
idx : 100, pred - ori : -0.280774
idx : 101, pred - ori : -0.263456
idx : 102, pred - ori : -0.242432
idx : 103, pred - ori : -0.247016
idx : 104, pred - ori : -0.281526
idx : 105, pred - ori : -0.280960
idx : 106, pred - ori : -0.274643
idx : 107, pred - ori : -0.231041
idx : 108, pred - ori : -0.221547
idx : 109, pred - ori : -0.251119
idx : 110, pred - ori : -0.225361
idx : 111, pred - ori : -0.213741
idx : 112, pred - ori : -0.195307
idx : 113, pred - ori : -0.207060
idx : 114, pred - ori : -0.231118
idx : 115, pred - ori : -0.245432
idx : 116, pred - ori : -0.224531
idx : 117, pred - ori : -0.225566
idx : 118, pred - ori : -0.202467
idx : 119, pred - ori : -0.214902
idx : 120, pred - ori : -0.230794
idx : 121, pred - ori : -0.226070
idx : 122, pred - ori : -0.224886
idx : 123, pred - ori : -0.238572
idx : 124, pred - ori : -0.318963
idx : 125, pred - ori : -0.318321
idx : 126, pred - ori : -0.308431
idx : 127, pred - ori : -0.392113
idx : 128, pred - ori : -0.427443
idx : 129, pred - ori : -0.413289
idx : 130, pred - ori : -0.356142
idx : 131, pred - ori : -0.395430
idx : 132, pred - ori : -0.398554
idx : 133, pred - ori : -0.352199
idx : 134, pred - ori : -0.328899
idx : 135, pred - ori : -0.368094
idx : 136, pred - ori : -0.368498
idx : 137, pred - ori : -0.350617
idx : 138, pred - ori : -0.332483
idx : 139, pred - ori : -0.350618
idx : 140, pred - ori : -0.305418
idx : 141, pred - ori : -0.273195
idx : 142, pred - ori : -0.289126
idx : 143, pred - ori : -0.266337
idx : 144, pred - ori : -0.312268
idx : 145, pred - ori : -0.332999
idx : 146, pred - ori : -0.376032
idx : 147, pred - ori : -0.374195
idx : 148, pred - ori : -0.406148
idx : 149, pred - ori : -0.352924
idx : 150, pred - ori : -0.329289
idx : 151, pred - ori : -0.311913
idx : 152, pred - ori : -0.350993
idx : 153, pred - ori : -0.335618
idx : 154, pred - ori : -0.309953
idx : 155, pred - ori : -0.288718
idx : 156, pred - ori : -0.294010
idx : 157, pred - ori : -0.265367
idx : 158, pred - ori : -0.231044
idx : 159, pred - ori : -0.205794
idx : 160, pred - ori : -0.251043
idx : 161, pred - ori : -0.182765
idx : 162, pred - ori : -0.266751
idx : 163, pred - ori : -0.243790
idx : 164, pred - ori : -0.241900
idx : 165, pred - ori : -0.293551
idx : 166, pred - ori : -0.276371
idx : 167, pred - ori : -0.240045
idx : 168, pred - ori : -0.279564
idx : 169, pred - ori : -0.339623
idx : 170, pred - ori : -0.342443
idx : 171, pred - ori : -0.365863
idx : 172, pred - ori : -0.265697
idx : 173, pred - ori : -0.221783
idx : 174, pred - ori : -0.228437
idx : 175, pred - ori : -0.194184
idx : 176, pred - ori : -0.169656
idx : 177, pred - ori : -0.140216
idx : 178, pred - ori : -0.160943
idx : 179, pred - ori : -0.174709
idx : 180, pred - ori : -0.199868
result_sum : 36.752865, mean(result_sum) : 0.204183
benefit : 180

 End check_performance !

Finish lg
Start kakao
End load_stock_and_preprocessing !

IN make_train_test_set 
train_data X shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 20, 1)
train_data Y shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 1)
valid_data X shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 20, 1)
valid_data Y shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 1)
test_data X shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 20, 1)
test_data Y shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 1)

End make_train_test_set !

IN make_model, print model <tensorflow.python.keras.engine.sequential.Sequential object at 0x7fadcbc1d250>
IN learning, print model <tensorflow.python.keras.engine.sequential.Sequential object at 0x7fadcbc1d250>
train_data X shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 20, 1)
train_data Y shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 1)
valid_data X shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 20, 1)
valid_data Y shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 1)
Epoch 1/50

      1/Unknown - 1s 1s/step - loss: 0.0022 - mse: 0.0043
9/9 [==============================] - 2s 49ms/step - loss: 0.0016 - mse: 0.0032 - val_loss: 0.0060 - val_mse: 0.0119

Epoch 00001: val_loss improved from inf to 0.00595, saving model to ./model/models/035720/035720.ckpt
Epoch 2/50

1/9 [==>...........................] - ETA: 0s - loss: 2.4801e-04 - mse: 4.9603e-04
9/9 [==============================] - 0s 9ms/step - loss: 3.3720e-04 - mse: 6.7440e-04 - val_loss: 0.0030 - val_mse: 0.0060

Epoch 00002: val_loss improved from 0.00595 to 0.00301, saving model to ./model/models/035720/035720.ckpt
Epoch 3/50

1/9 [==>...........................] - ETA: 0s - loss: 3.1403e-04 - mse: 6.2805e-04
9/9 [==============================] - 0s 9ms/step - loss: 3.2900e-04 - mse: 6.5799e-04 - val_loss: 0.0041 - val_mse: 0.0083

Epoch 00003: val_loss did not improve from 0.00301
Epoch 4/50

1/9 [==>...........................] - ETA: 0s - loss: 1.8199e-04 - mse: 3.6397e-04
9/9 [==============================] - 0s 9ms/step - loss: 2.3927e-04 - mse: 4.7854e-04 - val_loss: 0.0036 - val_mse: 0.0071

Epoch 00004: val_loss did not improve from 0.00301
Epoch 5/50

1/9 [==>...........................] - ETA: 0s - loss: 1.4655e-04 - mse: 2.9309e-04
9/9 [==============================] - 0s 9ms/step - loss: 1.7312e-04 - mse: 3.4625e-04 - val_loss: 0.0021 - val_mse: 0.0042

Epoch 00005: val_loss improved from 0.00301 to 0.00211, saving model to ./model/models/035720/035720.ckpt
Epoch 6/50

1/9 [==>...........................] - ETA: 0s - loss: 1.3535e-04 - mse: 2.7070e-04
9/9 [==============================] - 0s 9ms/step - loss: 1.2604e-04 - mse: 2.5208e-04 - val_loss: 0.0016 - val_mse: 0.0033

Epoch 00006: val_loss improved from 0.00211 to 0.00163, saving model to ./model/models/035720/035720.ckpt
Epoch 7/50

1/9 [==>...........................] - ETA: 0s - loss: 1.1133e-04 - mse: 2.2265e-04
9/9 [==============================] - 0s 9ms/step - loss: 8.7374e-05 - mse: 1.7475e-04 - val_loss: 0.0013 - val_mse: 0.0025

Epoch 00007: val_loss improved from 0.00163 to 0.00125, saving model to ./model/models/035720/035720.ckpt
Epoch 8/50

1/9 [==>...........................] - ETA: 0s - loss: 5.9926e-05 - mse: 1.1985e-04
9/9 [==============================] - 0s 8ms/step - loss: 7.4176e-05 - mse: 1.4835e-04 - val_loss: 8.9678e-04 - val_mse: 0.0018

Epoch 00008: val_loss improved from 0.00125 to 0.00090, saving model to ./model/models/035720/035720.ckpt
Epoch 9/50

1/9 [==>...........................] - ETA: 0s - loss: 6.1080e-05 - mse: 1.2216e-04
9/9 [==============================] - 0s 9ms/step - loss: 6.6760e-05 - mse: 1.3352e-04 - val_loss: 8.9170e-04 - val_mse: 0.0018

Epoch 00009: val_loss improved from 0.00090 to 0.00089, saving model to ./model/models/035720/035720.ckpt
Epoch 10/50

1/9 [==>...........................] - ETA: 0s - loss: 7.1562e-05 - mse: 1.4312e-04
9/9 [==============================] - 0s 8ms/step - loss: 7.4550e-05 - mse: 1.4910e-04 - val_loss: 8.0885e-04 - val_mse: 0.0016

Epoch 00010: val_loss improved from 0.00089 to 0.00081, saving model to ./model/models/035720/035720.ckpt
Epoch 11/50

1/9 [==>...........................] - ETA: 0s - loss: 8.1407e-05 - mse: 1.6281e-04
9/9 [==============================] - 0s 9ms/step - loss: 7.5264e-05 - mse: 1.5053e-04 - val_loss: 9.0695e-04 - val_mse: 0.0018

Epoch 00011: val_loss did not improve from 0.00081
Epoch 12/50

1/9 [==>...........................] - ETA: 0s - loss: 9.9111e-05 - mse: 1.9822e-04
9/9 [==============================] - 0s 8ms/step - loss: 7.5616e-05 - mse: 1.5123e-04 - val_loss: 8.2336e-04 - val_mse: 0.0016

Epoch 00012: val_loss did not improve from 0.00081
Epoch 13/50

1/9 [==>...........................] - ETA: 0s - loss: 7.1950e-05 - mse: 1.4390e-04
9/9 [==============================] - 0s 9ms/step - loss: 6.6754e-05 - mse: 1.3351e-04 - val_loss: 9.1290e-04 - val_mse: 0.0018

Epoch 00013: val_loss did not improve from 0.00081
Epoch 14/50

1/9 [==>...........................] - ETA: 0s - loss: 5.8246e-05 - mse: 1.1649e-04
9/9 [==============================] - 0s 8ms/step - loss: 6.7731e-05 - mse: 1.3546e-04 - val_loss: 8.5993e-04 - val_mse: 0.0017

Epoch 00014: val_loss did not improve from 0.00081
Epoch 15/50

1/9 [==>...........................] - ETA: 0s - loss: 7.1324e-05 - mse: 1.4265e-04
9/9 [==============================] - 0s 9ms/step - loss: 7.1896e-05 - mse: 1.4379e-04 - val_loss: 9.3641e-04 - val_mse: 0.0019

Epoch 00015: val_loss did not improve from 0.00081
Epoch 16/50

1/9 [==>...........................] - ETA: 0s - loss: 5.2096e-05 - mse: 1.0419e-04
9/9 [==============================] - 0s 8ms/step - loss: 6.3539e-05 - mse: 1.2708e-04 - val_loss: 8.8707e-04 - val_mse: 0.0018

Epoch 00016: val_loss did not improve from 0.00081
Epoch 17/50

1/9 [==>...........................] - ETA: 0s - loss: 8.3105e-05 - mse: 1.6621e-04
9/9 [==============================] - 0s 8ms/step - loss: 7.3232e-05 - mse: 1.4646e-04 - val_loss: 9.6995e-04 - val_mse: 0.0019

Epoch 00017: val_loss did not improve from 0.00081
Epoch 18/50

1/9 [==>...........................] - ETA: 0s - loss: 8.6239e-05 - mse: 1.7248e-04
9/9 [==============================] - 0s 8ms/step - loss: 7.1449e-05 - mse: 1.4290e-04 - val_loss: 8.2366e-04 - val_mse: 0.0016

Epoch 00018: val_loss did not improve from 0.00081
Epoch 19/50

1/9 [==>...........................] - ETA: 0s - loss: 6.4870e-05 - mse: 1.2974e-04
9/9 [==============================] - 0s 8ms/step - loss: 6.4242e-05 - mse: 1.2848e-04 - val_loss: 8.4322e-04 - val_mse: 0.0017

Epoch 00019: val_loss did not improve from 0.00081
Epoch 20/50

1/9 [==>...........................] - ETA: 0s - loss: 8.9462e-05 - mse: 1.7892e-04
9/9 [==============================] - 0s 9ms/step - loss: 6.6347e-05 - mse: 1.3269e-04 - val_loss: 7.8648e-04 - val_mse: 0.0016

Epoch 00020: val_loss improved from 0.00081 to 0.00079, saving model to ./model/models/035720/035720.ckpt
Epoch 21/50

1/9 [==>...........................] - ETA: 0s - loss: 6.9315e-05 - mse: 1.3863e-04
9/9 [==============================] - 0s 9ms/step - loss: 6.5455e-05 - mse: 1.3091e-04 - val_loss: 7.9500e-04 - val_mse: 0.0016

Epoch 00021: val_loss did not improve from 0.00079
Epoch 22/50

1/9 [==>...........................] - ETA: 0s - loss: 5.2023e-05 - mse: 1.0405e-04
9/9 [==============================] - 0s 8ms/step - loss: 6.1644e-05 - mse: 1.2329e-04 - val_loss: 8.1699e-04 - val_mse: 0.0016

Epoch 00022: val_loss did not improve from 0.00079
Epoch 23/50

1/9 [==>...........................] - ETA: 0s - loss: 8.6457e-05 - mse: 1.7291e-04
9/9 [==============================] - 0s 8ms/step - loss: 7.0460e-05 - mse: 1.4092e-04 - val_loss: 8.5594e-04 - val_mse: 0.0017

Epoch 00023: val_loss did not improve from 0.00079
Epoch 24/50

1/9 [==>...........................] - ETA: 0s - loss: 5.7212e-05 - mse: 1.1442e-04
9/9 [==============================] - 0s 8ms/step - loss: 6.2113e-05 - mse: 1.2423e-04 - val_loss: 7.4911e-04 - val_mse: 0.0015

Epoch 00024: val_loss improved from 0.00079 to 0.00075, saving model to ./model/models/035720/035720.ckpt
Epoch 25/50

1/9 [==>...........................] - ETA: 0s - loss: 6.2499e-05 - mse: 1.2500e-04
9/9 [==============================] - 0s 8ms/step - loss: 6.4459e-05 - mse: 1.2892e-04 - val_loss: 9.3988e-04 - val_mse: 0.0019

Epoch 00025: val_loss did not improve from 0.00075
Epoch 26/50

1/9 [==>...........................] - ETA: 0s - loss: 3.3344e-05 - mse: 6.6688e-05
9/9 [==============================] - 0s 9ms/step - loss: 5.9742e-05 - mse: 1.1948e-04 - val_loss: 7.6417e-04 - val_mse: 0.0015

Epoch 00026: val_loss did not improve from 0.00075
Epoch 27/50

1/9 [==>...........................] - ETA: 0s - loss: 6.2381e-05 - mse: 1.2476e-04
9/9 [==============================] - 0s 9ms/step - loss: 6.3396e-05 - mse: 1.2679e-04 - val_loss: 9.9444e-04 - val_mse: 0.0020

Epoch 00027: val_loss did not improve from 0.00075
Epoch 28/50

1/9 [==>...........................] - ETA: 0s - loss: 6.6101e-05 - mse: 1.3220e-04
9/9 [==============================] - 0s 9ms/step - loss: 6.9439e-05 - mse: 1.3888e-04 - val_loss: 7.1104e-04 - val_mse: 0.0014

Epoch 00028: val_loss improved from 0.00075 to 0.00071, saving model to ./model/models/035720/035720.ckpt
Epoch 29/50

1/9 [==>...........................] - ETA: 0s - loss: 1.0727e-04 - mse: 2.1454e-04
9/9 [==============================] - 0s 8ms/step - loss: 7.2711e-05 - mse: 1.4542e-04 - val_loss: 8.4881e-04 - val_mse: 0.0017

Epoch 00029: val_loss did not improve from 0.00071
Epoch 30/50

1/9 [==>...........................] - ETA: 0s - loss: 4.9872e-05 - mse: 9.9743e-05
9/9 [==============================] - 0s 8ms/step - loss: 5.5806e-05 - mse: 1.1161e-04 - val_loss: 7.6375e-04 - val_mse: 0.0015

Epoch 00030: val_loss did not improve from 0.00071
Epoch 31/50

1/9 [==>...........................] - ETA: 0s - loss: 4.5079e-05 - mse: 9.0158e-05
9/9 [==============================] - 0s 8ms/step - loss: 5.6485e-05 - mse: 1.1297e-04 - val_loss: 7.1702e-04 - val_mse: 0.0014

Epoch 00031: val_loss did not improve from 0.00071
Epoch 32/50

1/9 [==>...........................] - ETA: 0s - loss: 5.4730e-05 - mse: 1.0946e-04
9/9 [==============================] - 0s 9ms/step - loss: 5.7243e-05 - mse: 1.1449e-04 - val_loss: 7.7619e-04 - val_mse: 0.0016

Epoch 00032: val_loss did not improve from 0.00071
Epoch 33/50

1/9 [==>...........................] - ETA: 0s - loss: 5.6925e-05 - mse: 1.1385e-04
9/9 [==============================] - 0s 9ms/step - loss: 6.0218e-05 - mse: 1.2044e-04 - val_loss: 8.2730e-04 - val_mse: 0.0017

Epoch 00033: val_loss did not improve from 0.00071
Epoch 34/50

1/9 [==>...........................] - ETA: 0s - loss: 7.3683e-05 - mse: 1.4737e-04
9/9 [==============================] - 0s 9ms/step - loss: 6.1921e-05 - mse: 1.2384e-04 - val_loss: 7.5595e-04 - val_mse: 0.0015

Epoch 00034: val_loss did not improve from 0.00071
Epoch 35/50

1/9 [==>...........................] - ETA: 0s - loss: 7.3085e-05 - mse: 1.4617e-04
9/9 [==============================] - 0s 8ms/step - loss: 5.9334e-05 - mse: 1.1867e-04 - val_loss: 7.8281e-04 - val_mse: 0.0016

Epoch 00035: val_loss did not improve from 0.00071
Epoch 36/50

1/9 [==>...........................] - ETA: 0s - loss: 7.3673e-05 - mse: 1.4735e-04
9/9 [==============================] - 0s 8ms/step - loss: 6.0759e-05 - mse: 1.2152e-04 - val_loss: 6.7676e-04 - val_mse: 0.0014

Epoch 00036: val_loss improved from 0.00071 to 0.00068, saving model to ./model/models/035720/035720.ckpt
Epoch 37/50

1/9 [==>...........................] - ETA: 0s - loss: 8.1382e-05 - mse: 1.6276e-04
9/9 [==============================] - 0s 9ms/step - loss: 6.0088e-05 - mse: 1.2018e-04 - val_loss: 7.9139e-04 - val_mse: 0.0016

Epoch 00037: val_loss did not improve from 0.00068
Epoch 38/50

1/9 [==>...........................] - ETA: 0s - loss: 6.4655e-05 - mse: 1.2931e-04
9/9 [==============================] - 0s 9ms/step - loss: 6.2516e-05 - mse: 1.2503e-04 - val_loss: 6.5194e-04 - val_mse: 0.0013

Epoch 00038: val_loss improved from 0.00068 to 0.00065, saving model to ./model/models/035720/035720.ckpt
Epoch 39/50

1/9 [==>...........................] - ETA: 0s - loss: 4.8530e-05 - mse: 9.7061e-05
9/9 [==============================] - 0s 8ms/step - loss: 5.6840e-05 - mse: 1.1368e-04 - val_loss: 7.6091e-04 - val_mse: 0.0015

Epoch 00039: val_loss did not improve from 0.00065
Epoch 40/50

1/9 [==>...........................] - ETA: 0s - loss: 2.8130e-05 - mse: 5.6260e-05
9/9 [==============================] - 0s 8ms/step - loss: 4.5191e-05 - mse: 9.0382e-05 - val_loss: 7.7511e-04 - val_mse: 0.0016

Epoch 00040: val_loss did not improve from 0.00065
Epoch 41/50

1/9 [==>...........................] - ETA: 0s - loss: 6.0427e-05 - mse: 1.2085e-04
9/9 [==============================] - 0s 8ms/step - loss: 5.8800e-05 - mse: 1.1760e-04 - val_loss: 6.0385e-04 - val_mse: 0.0012

Epoch 00041: val_loss improved from 0.00065 to 0.00060, saving model to ./model/models/035720/035720.ckpt
Epoch 42/50

1/9 [==>...........................] - ETA: 0s - loss: 4.5059e-05 - mse: 9.0118e-05
9/9 [==============================] - 0s 9ms/step - loss: 5.9520e-05 - mse: 1.1904e-04 - val_loss: 8.5564e-04 - val_mse: 0.0017

Epoch 00042: val_loss did not improve from 0.00060
Epoch 43/50

1/9 [==>...........................] - ETA: 0s - loss: 5.7667e-05 - mse: 1.1533e-04
9/9 [==============================] - 0s 8ms/step - loss: 6.4820e-05 - mse: 1.2964e-04 - val_loss: 6.1426e-04 - val_mse: 0.0012

Epoch 00043: val_loss did not improve from 0.00060
Epoch 44/50

1/9 [==>...........................] - ETA: 0s - loss: 7.9427e-05 - mse: 1.5885e-04
9/9 [==============================] - 0s 9ms/step - loss: 5.9456e-05 - mse: 1.1891e-04 - val_loss: 6.8356e-04 - val_mse: 0.0014

Epoch 00044: val_loss did not improve from 0.00060
Epoch 45/50

1/9 [==>...........................] - ETA: 0s - loss: 3.5663e-05 - mse: 7.1326e-05
9/9 [==============================] - 0s 8ms/step - loss: 4.3512e-05 - mse: 8.7025e-05 - val_loss: 6.8288e-04 - val_mse: 0.0014

Epoch 00045: val_loss did not improve from 0.00060
Epoch 46/50

1/9 [==>...........................] - ETA: 0s - loss: 5.4083e-05 - mse: 1.0817e-04
9/9 [==============================] - 0s 8ms/step - loss: 5.3950e-05 - mse: 1.0790e-04 - val_loss: 6.0445e-04 - val_mse: 0.0012

Epoch 00046: val_loss did not improve from 0.00060
Epoch 47/50

1/9 [==>...........................] - ETA: 0s - loss: 6.4956e-05 - mse: 1.2991e-04
9/9 [==============================] - 0s 8ms/step - loss: 5.0981e-05 - mse: 1.0196e-04 - val_loss: 7.1893e-04 - val_mse: 0.0014

Epoch 00047: val_loss did not improve from 0.00060
Epoch 48/50

1/9 [==>...........................] - ETA: 0s - loss: 6.6969e-05 - mse: 1.3394e-04
9/9 [==============================] - 0s 8ms/step - loss: 5.9427e-05 - mse: 1.1885e-04 - val_loss: 5.5091e-04 - val_mse: 0.0011

Epoch 00048: val_loss improved from 0.00060 to 0.00055, saving model to ./model/models/035720/035720.ckpt
Epoch 49/50

1/9 [==>...........................] - ETA: 0s - loss: 3.5329e-05 - mse: 7.0658e-05
9/9 [==============================] - 0s 8ms/step - loss: 5.0155e-05 - mse: 1.0031e-04 - val_loss: 5.9180e-04 - val_mse: 0.0012

Epoch 00049: val_loss did not improve from 0.00055
Epoch 50/50

1/9 [==>...........................] - ETA: 0s - loss: 4.2145e-05 - mse: 8.4290e-05
9/9 [==============================] - 0s 9ms/step - loss: 5.3180e-05 - mse: 1.0636e-04 - val_loss: 6.8077e-04 - val_mse: 0.0014

Epoch 00050: val_loss did not improve from 0.00055
End learning !
End make_model !

035720 Start check_bias_variance !
Test about valid_set
End load_moodel !

End prediction !

len_ori : 50, len_pred : 50
======= difference ======= 
idx : 1, pred - ori : 0.031650
idx : 2, pred - ori : -0.000647
idx : 3, pred - ori : 0.000264
idx : 4, pred - ori : 0.007789
idx : 5, pred - ori : 0.005356
idx : 6, pred - ori : 0.003871
idx : 7, pred - ori : -0.001987
idx : 8, pred - ori : 0.011619
idx : 9, pred - ori : -0.004018
idx : 10, pred - ori : -0.003783
idx : 11, pred - ori : -0.010361
idx : 12, pred - ori : -0.005463
idx : 13, pred - ori : 0.001153
idx : 14, pred - ori : 0.003325
idx : 15, pred - ori : -0.002835
idx : 16, pred - ori : 0.006866
idx : 17, pred - ori : 0.003158
idx : 18, pred - ori : -0.009815
idx : 19, pred - ori : -0.023708
idx : 20, pred - ori : -0.026056
idx : 21, pred - ori : -0.021690
idx : 22, pred - ori : -0.019367
idx : 23, pred - ori : -0.034101
idx : 24, pred - ori : -0.021294
idx : 25, pred - ori : -0.017486
idx : 26, pred - ori : -0.013604
idx : 27, pred - ori : -0.007111
idx : 28, pred - ori : -0.008919
idx : 29, pred - ori : -0.036164
idx : 30, pred - ori : -0.045641
idx : 31, pred - ori : -0.038541
idx : 32, pred - ori : -0.034344
idx : 33, pred - ori : -0.044069
idx : 34, pred - ori : -0.040568
idx : 35, pred - ori : -0.052198
idx : 36, pred - ori : -0.034255
idx : 37, pred - ori : -0.025133
idx : 38, pred - ori : -0.014386
idx : 39, pred - ori : -0.036171
idx : 40, pred - ori : -0.042752
idx : 41, pred - ori : -0.058114
idx : 42, pred - ori : -0.098771
idx : 43, pred - ori : -0.092672
idx : 44, pred - ori : -0.056734
idx : 45, pred - ori : -0.059276
idx : 46, pred - ori : -0.039539
idx : 47, pred - ori : -0.029446
idx : 48, pred - ori : -0.007596
idx : 49, pred - ori : 0.022061
idx : 50, pred - ori : 0.015332
result_sum : 1.231058, mean(result_sum) : 0.024621
benefit : 38

 End check_performance !

Test about test_set
End load_moodel !

End prediction !

len_ori : 180, len_pred : 180
======= difference ======= 
idx : 1, pred - ori : -0.036260
idx : 2, pred - ori : -0.048060
idx : 3, pred - ori : -0.065248
idx : 4, pred - ori : -0.099462
idx : 5, pred - ori : -0.152775
idx : 6, pred - ori : -0.135104
idx : 7, pred - ori : -0.107511
idx : 8, pred - ori : -0.066085
idx : 9, pred - ori : -0.038112
idx : 10, pred - ori : 0.013959
idx : 11, pred - ori : 0.014854
idx : 12, pred - ori : 0.056658
idx : 13, pred - ori : 0.040947
idx : 14, pred - ori : 0.036840
idx : 15, pred - ori : 0.005208
idx : 16, pred - ori : 0.018393
idx : 17, pred - ori : 0.011690
idx : 18, pred - ori : 0.005737
idx : 19, pred - ori : 0.001002
idx : 20, pred - ori : 0.003043
idx : 21, pred - ori : -0.022422
idx : 22, pred - ori : -0.072344
idx : 23, pred - ori : -0.074436
idx : 24, pred - ori : -0.065462
idx : 25, pred - ori : -0.039000
idx : 26, pred - ori : -0.004542
idx : 27, pred - ori : -0.003998
idx : 28, pred - ori : 0.010219
idx : 29, pred - ori : 0.010392
idx : 30, pred - ori : -0.001431
idx : 31, pred - ori : -0.004667
idx : 32, pred - ori : -0.038612
idx : 33, pred - ori : -0.029851
idx : 34, pred - ori : 0.003822
idx : 35, pred - ori : -0.003974
idx : 36, pred - ori : -0.025173
idx : 37, pred - ori : -0.022020
idx : 38, pred - ori : -0.041560
idx : 39, pred - ori : -0.079574
idx : 40, pred - ori : -0.058742
idx : 41, pred - ori : -0.051271
idx : 42, pred - ori : -0.027519
idx : 43, pred - ori : -0.045898
idx : 44, pred - ori : -0.030231
idx : 45, pred - ori : -0.003890
idx : 46, pred - ori : 0.026867
idx : 47, pred - ori : 0.032422
idx : 48, pred - ori : 0.046916
idx : 49, pred - ori : 0.041255
idx : 50, pred - ori : 0.054499
idx : 51, pred - ori : 0.062283
idx : 52, pred - ori : 0.038998
idx : 53, pred - ori : 0.043284
idx : 54, pred - ori : 0.053335
idx : 55, pred - ori : 0.044123
idx : 56, pred - ori : 0.058730
idx : 57, pred - ori : 0.080905
idx : 58, pred - ori : 0.043942
idx : 59, pred - ori : 0.069894
idx : 60, pred - ori : 0.063784
idx : 61, pred - ori : 0.016480
idx : 62, pred - ori : 0.021127
idx : 63, pred - ori : 0.005412
idx : 64, pred - ori : -0.021257
idx : 65, pred - ori : -0.018752
idx : 66, pred - ori : -0.010343
idx : 67, pred - ori : 0.011463
idx : 68, pred - ori : 0.011654
idx : 69, pred - ori : 0.022514
idx : 70, pred - ori : 0.038330
idx : 71, pred - ori : 0.048430
idx : 72, pred - ori : 0.055602
idx : 73, pred - ori : 0.052308
idx : 74, pred - ori : 0.045354
idx : 75, pred - ori : 0.051457
idx : 76, pred - ori : 0.068014
idx : 77, pred - ori : 0.086440
idx : 78, pred - ori : 0.067002
idx : 79, pred - ori : 0.029747
idx : 80, pred - ori : 0.033438
idx : 81, pred - ori : 0.061068
idx : 82, pred - ori : 0.044517
idx : 83, pred - ori : 0.034138
idx : 84, pred - ori : -0.024036
idx : 85, pred - ori : -0.030289
idx : 86, pred - ori : -0.046277
idx : 87, pred - ori : -0.042222
idx : 88, pred - ori : -0.000329
idx : 89, pred - ori : 0.007079
idx : 90, pred - ori : 0.006036
idx : 91, pred - ori : -0.010430
idx : 92, pred - ori : 0.003205
idx : 93, pred - ori : 0.005131
idx : 94, pred - ori : -0.000858
idx : 95, pred - ori : 0.000637
idx : 96, pred - ori : 0.003862
idx : 97, pred - ori : 0.002807
idx : 98, pred - ori : -0.009477
idx : 99, pred - ori : 0.008043
idx : 100, pred - ori : -0.006467
idx : 101, pred - ori : -0.000770
idx : 102, pred - ori : 0.013259
idx : 103, pred - ori : 0.000892
idx : 104, pred - ori : 0.005997
idx : 105, pred - ori : 0.005388
idx : 106, pred - ori : -0.029217
idx : 107, pred - ori : -0.015417
idx : 108, pred - ori : 0.013841
idx : 109, pred - ori : 0.015981
idx : 110, pred - ori : 0.026586
idx : 111, pred - ori : 0.017738
idx : 112, pred - ori : 0.021401
idx : 113, pred - ori : 0.026154
idx : 114, pred - ori : 0.023370
idx : 115, pred - ori : 0.028900
idx : 116, pred - ori : 0.032276
idx : 117, pred - ori : 0.000815
idx : 118, pred - ori : 0.009112
idx : 119, pred - ori : 0.005867
idx : 120, pred - ori : 0.015957
idx : 121, pred - ori : 0.017249
idx : 122, pred - ori : -0.008911
idx : 123, pred - ori : -0.019022
idx : 124, pred - ori : -0.031032
idx : 125, pred - ori : -0.018475
idx : 126, pred - ori : -0.020525
idx : 127, pred - ori : -0.031636
idx : 128, pred - ori : -0.101399
idx : 129, pred - ori : -0.135504
idx : 130, pred - ori : -0.131843
idx : 131, pred - ori : -0.106214
idx : 132, pred - ori : -0.082796
idx : 133, pred - ori : -0.032856
idx : 134, pred - ori : 0.003778
idx : 135, pred - ori : -0.017851
idx : 136, pred - ori : -0.021379
idx : 137, pred - ori : -0.039727
idx : 138, pred - ori : -0.054773
idx : 139, pred - ori : -0.074244
idx : 140, pred - ori : -0.034419
idx : 141, pred - ori : -0.036446
idx : 142, pred - ori : -0.012011
idx : 143, pred - ori : 0.032159
idx : 144, pred - ori : 0.033379
idx : 145, pred - ori : 0.021302
idx : 146, pred - ori : -0.019763
idx : 147, pred - ori : 0.000368
idx : 148, pred - ori : -0.001150
idx : 149, pred - ori : -0.004831
idx : 150, pred - ori : -0.015461
idx : 151, pred - ori : -0.080179
idx : 152, pred - ori : -0.103748
idx : 153, pred - ori : -0.122428
idx : 154, pred - ori : -0.095496
idx : 155, pred - ori : -0.063975
idx : 156, pred - ori : -0.058674
idx : 157, pred - ori : -0.016893
idx : 158, pred - ori : -0.002181
idx : 159, pred - ori : 0.033778
idx : 160, pred - ori : 0.004341
idx : 161, pred - ori : -0.003723
idx : 162, pred - ori : -0.014000
idx : 163, pred - ori : -0.017161
idx : 164, pred - ori : 0.009774
idx : 165, pred - ori : 0.035393
idx : 166, pred - ori : 0.072750
idx : 167, pred - ori : 0.095956
idx : 168, pred - ori : 0.040848
idx : 169, pred - ori : -0.012266
idx : 170, pred - ori : -0.020534
idx : 171, pred - ori : -0.015646
idx : 172, pred - ori : -0.016515
idx : 173, pred - ori : -0.030444
idx : 174, pred - ori : -0.057946
idx : 175, pred - ori : -0.039180
idx : 176, pred - ori : -0.037535
idx : 177, pred - ori : -0.023966
idx : 178, pred - ori : -0.024938
idx : 179, pred - ori : -0.003281
idx : 180, pred - ori : -0.026073
result_sum : 6.200325, mean(result_sum) : 0.034446
benefit : 93

 End check_performance !

Finish kakao
Start naver
End load_stock_and_preprocessing !

IN make_train_test_set 
train_data X shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 20, 1)
train_data Y shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 1)
valid_data X shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 20, 1)
valid_data Y shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 1)
test_data X shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 20, 1)
test_data Y shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 1)

End make_train_test_set !

IN make_model, print model <tensorflow.python.keras.engine.sequential.Sequential object at 0x7fae1012e090>
IN learning, print model <tensorflow.python.keras.engine.sequential.Sequential object at 0x7fae1012e090>
train_data X shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 20, 1)
train_data Y shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 1)
valid_data X shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 20, 1)
valid_data Y shape( BATCH_SIZE, WINDOW_SIZE, feature ) : (32, 1)
Epoch 1/50

      1/Unknown - 1s 1s/step - loss: 0.0116 - mse: 0.0232
9/9 [==============================] - 2s 49ms/step - loss: 0.0112 - mse: 0.0225 - val_loss: 0.0389 - val_mse: 0.0777

Epoch 00001: val_loss improved from inf to 0.03885, saving model to ./model/models/035420/035420.ckpt
Epoch 2/50

1/9 [==>...........................] - ETA: 0s - loss: 0.0104 - mse: 0.0207
9/9 [==============================] - 0s 9ms/step - loss: 0.0083 - mse: 0.0166 - val_loss: 0.0309 - val_mse: 0.0618

Epoch 00002: val_loss improved from 0.03885 to 0.03088, saving model to ./model/models/035420/035420.ckpt
Epoch 3/50

1/9 [==>...........................] - ETA: 0s - loss: 0.0063 - mse: 0.0126
9/9 [==============================] - 0s 8ms/step - loss: 0.0056 - mse: 0.0111 - val_loss: 0.0221 - val_mse: 0.0441

Epoch 00003: val_loss improved from 0.03088 to 0.02207, saving model to ./model/models/035420/035420.ckpt
Epoch 4/50

1/9 [==>...........................] - ETA: 0s - loss: 0.0034 - mse: 0.0069
9/9 [==============================] - 0s 9ms/step - loss: 0.0030 - mse: 0.0059 - val_loss: 0.0132 - val_mse: 0.0263

Epoch 00004: val_loss improved from 0.02207 to 0.01316, saving model to ./model/models/035420/035420.ckpt
Epoch 5/50

1/9 [==>...........................] - ETA: 0s - loss: 0.0018 - mse: 0.0037
9/9 [==============================] - 0s 9ms/step - loss: 0.0018 - mse: 0.0036 - val_loss: 0.0066 - val_mse: 0.0131

Epoch 00005: val_loss improved from 0.01316 to 0.00656, saving model to ./model/models/035420/035420.ckpt
Epoch 6/50

1/9 [==>...........................] - ETA: 0s - loss: 0.0016 - mse: 0.0032
9/9 [==============================] - 0s 8ms/step - loss: 0.0015 - mse: 0.0030 - val_loss: 0.0053 - val_mse: 0.0106

Epoch 00006: val_loss improved from 0.00656 to 0.00532, saving model to ./model/models/035420/035420.ckpt
Epoch 7/50

1/9 [==>...........................] - ETA: 0s - loss: 0.0012 - mse: 0.0023
9/9 [==============================] - 0s 8ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 0.0048 - val_mse: 0.0096

Epoch 00007: val_loss improved from 0.00532 to 0.00482, saving model to ./model/models/035420/035420.ckpt
Epoch 8/50

1/9 [==>...........................] - ETA: 0s - loss: 7.0630e-04 - mse: 0.0014
9/9 [==============================] - 0s 8ms/step - loss: 7.2324e-04 - mse: 0.0014 - val_loss: 0.0034 - val_mse: 0.0068

Epoch 00008: val_loss improved from 0.00482 to 0.00339, saving model to ./model/models/035420/035420.ckpt
Epoch 9/50

1/9 [==>...........................] - ETA: 0s - loss: 5.7080e-04 - mse: 0.0011
9/9 [==============================] - 0s 8ms/step - loss: 4.2987e-04 - mse: 8.5974e-04 - val_loss: 0.0020 - val_mse: 0.0040

Epoch 00009: val_loss improved from 0.00339 to 0.00202, saving model to ./model/models/035420/035420.ckpt
Epoch 10/50

1/9 [==>...........................] - ETA: 0s - loss: 2.3593e-04 - mse: 4.7187e-04
9/9 [==============================] - 0s 9ms/step - loss: 2.3162e-04 - mse: 4.6324e-04 - val_loss: 0.0017 - val_mse: 0.0033

Epoch 00010: val_loss improved from 0.00202 to 0.00167, saving model to ./model/models/035420/035420.ckpt
Epoch 11/50

1/9 [==>...........................] - ETA: 0s - loss: 1.0774e-04 - mse: 2.1548e-04
9/9 [==============================] - 0s 10ms/step - loss: 1.6216e-04 - mse: 3.2432e-04 - val_loss: 0.0013 - val_mse: 0.0027

Epoch 00011: val_loss improved from 0.00167 to 0.00134, saving model to ./model/models/035420/035420.ckpt
Epoch 12/50

1/9 [==>...........................] - ETA: 0s - loss: 2.5421e-04 - mse: 5.0842e-04
9/9 [==============================] - 0s 9ms/step - loss: 1.9030e-04 - mse: 3.8060e-04 - val_loss: 0.0014 - val_mse: 0.0028

Epoch 00012: val_loss did not improve from 0.00134
Epoch 13/50

1/9 [==>...........................] - ETA: 0s - loss: 1.8776e-04 - mse: 3.7552e-04
9/9 [==============================] - 0s 9ms/step - loss: 1.6892e-04 - mse: 3.3783e-04 - val_loss: 0.0015 - val_mse: 0.0030

Epoch 00013: val_loss did not improve from 0.00134
Epoch 14/50

1/9 [==>...........................] - ETA: 0s - loss: 1.4031e-04 - mse: 2.8062e-04
9/9 [==============================] - 0s 8ms/step - loss: 1.4243e-04 - mse: 2.8485e-04 - val_loss: 0.0017 - val_mse: 0.0033

Epoch 00014: val_loss did not improve from 0.00134
Epoch 15/50

1/9 [==>...........................] - ETA: 0s - loss: 1.8715e-04 - mse: 3.7430e-04
9/9 [==============================] - 0s 8ms/step - loss: 1.4900e-04 - mse: 2.9800e-04 - val_loss: 0.0016 - val_mse: 0.0032

Epoch 00015: val_loss did not improve from 0.00134
Epoch 16/50

1/9 [==>...........................] - ETA: 0s - loss: 1.3164e-04 - mse: 2.6327e-04
9/9 [==============================] - 0s 9ms/step - loss: 1.4096e-04 - mse: 2.8192e-04 - val_loss: 0.0017 - val_mse: 0.0034

Epoch 00016: val_loss did not improve from 0.00134
Epoch 17/50

1/9 [==>...........................] - ETA: 0s - loss: 1.4279e-04 - mse: 2.8558e-04
9/9 [==============================] - 0s 8ms/step - loss: 1.5241e-04 - mse: 3.0483e-04 - val_loss: 0.0015 - val_mse: 0.0031

Epoch 00017: val_loss did not improve from 0.00134
Epoch 18/50

1/9 [==>...........................] - ETA: 0s - loss: 1.2222e-04 - mse: 2.4444e-04
9/9 [==============================] - 0s 9ms/step - loss: 1.3917e-04 - mse: 2.7835e-04 - val_loss: 0.0016 - val_mse: 0.0033

Epoch 00018: val_loss did not improve from 0.00134
Epoch 19/50

1/9 [==>...........................] - ETA: 0s - loss: 1.9948e-04 - mse: 3.9896e-04
9/9 [==============================] - 0s 9ms/step - loss: 1.6166e-04 - mse: 3.2333e-04 - val_loss: 0.0016 - val_mse: 0.0032

Epoch 00019: val_loss did not improve from 0.00134
Epoch 20/50

1/9 [==>...........................] - ETA: 0s - loss: 1.2725e-04 - mse: 2.5451e-04
9/9 [==============================] - 0s 8ms/step - loss: 1.3265e-04 - mse: 2.6531e-04 - val_loss: 0.0015 - val_mse: 0.0030

Epoch 00020: val_loss did not improve from 0.00134
Epoch 21/50

1/9 [==>...........................] - ETA: 0s - loss: 1.4002e-04 - mse: 2.8005e-04
9/9 [==============================] - 0s 8ms/step - loss: 1.4749e-04 - mse: 2.9498e-04 - val_loss: 0.0017 - val_mse: 0.0033

Epoch 00021: val_loss did not improve from 0.00134
End learning !
End make_model !

035420 Start check_bias_variance !
Test about valid_set
End load_moodel !

End prediction !

len_ori : 50, len_pred : 50
======= difference ======= 
idx : 1, pred - ori : 0.090615
idx : 2, pred - ori : 0.035563
idx : 3, pred - ori : 0.028195
idx : 4, pred - ori : 0.032607
idx : 5, pred - ori : -0.011685
idx : 6, pred - ori : -0.008721
idx : 7, pred - ori : -0.036189
idx : 8, pred - ori : -0.011631
idx : 9, pred - ori : -0.046732
idx : 10, pred - ori : -0.038164
idx : 11, pred - ori : -0.039055
idx : 12, pred - ori : -0.022477
idx : 13, pred - ori : -0.008263
idx : 14, pred - ori : -0.007609
idx : 15, pred - ori : -0.000738
idx : 16, pred - ori : 0.003151
idx : 17, pred - ori : -0.003071
idx : 18, pred - ori : -0.007500
idx : 19, pred - ori : -0.033743
idx : 20, pred - ori : -0.033122
idx : 21, pred - ori : -0.024701
idx : 22, pred - ori : -0.031262
idx : 23, pred - ori : -0.052867
idx : 24, pred - ori : -0.055142
idx : 25, pred - ori : -0.065441
idx : 26, pred - ori : -0.060025
idx : 27, pred - ori : -0.051156
idx : 28, pred - ori : -0.049385
idx : 29, pred - ori : -0.086062
idx : 30, pred - ori : -0.090049
idx : 31, pred - ori : -0.077570
idx : 32, pred - ori : -0.071885
idx : 33, pred - ori : -0.081096
idx : 34, pred - ori : -0.069838
idx : 35, pred - ori : -0.064298
idx : 36, pred - ori : -0.036813
idx : 37, pred - ori : -0.037523
idx : 38, pred - ori : -0.026828
idx : 39, pred - ori : -0.051178
idx : 40, pred - ori : -0.056963
idx : 41, pred - ori : -0.071271
idx : 42, pred - ori : -0.101507
idx : 43, pred - ori : -0.088459
idx : 44, pred - ori : -0.047008
idx : 45, pred - ori : -0.082459
idx : 46, pred - ori : -0.027863
idx : 47, pred - ori : -0.062038
idx : 48, pred - ori : -0.047515
idx : 49, pred - ori : -0.015798
idx : 50, pred - ori : -0.037583
result_sum : 2.220414, mean(result_sum) : 0.044408
benefit : 45

 End check_performance !

Test about test_set
End load_moodel !

End prediction !

len_ori : 180, len_pred : 180
======= difference ======= 
idx : 1, pred - ori : -0.124976
idx : 2, pred - ori : -0.134848
idx : 3, pred - ori : -0.124237
idx : 4, pred - ori : -0.130769
idx : 5, pred - ori : -0.144182
idx : 6, pred - ori : -0.179544
idx : 7, pred - ori : -0.168447
idx : 8, pred - ori : -0.129738
idx : 9, pred - ori : -0.124033
idx : 10, pred - ori : -0.075472
idx : 11, pred - ori : -0.084496
idx : 12, pred - ori : -0.039463
idx : 13, pred - ori : -0.064881
idx : 14, pred - ori : -0.066079
idx : 15, pred - ori : -0.115716
idx : 16, pred - ori : -0.105469
idx : 17, pred - ori : -0.117330
idx : 18, pred - ori : -0.127716
idx : 19, pred - ori : -0.140043
idx : 20, pred - ori : -0.144984
idx : 21, pred - ori : -0.166969
idx : 22, pred - ori : -0.210358
idx : 23, pred - ori : -0.195347
idx : 24, pred - ori : -0.200397
idx : 25, pred - ori : -0.225300
idx : 26, pred - ori : -0.194515
idx : 27, pred - ori : -0.189974
idx : 28, pred - ori : -0.180406
idx : 29, pred - ori : -0.156296
idx : 30, pred - ori : -0.161576
idx : 31, pred - ori : -0.153243
idx : 32, pred - ori : -0.160917
idx : 33, pred - ori : -0.184869
idx : 34, pred - ori : -0.151219
idx : 35, pred - ori : -0.173705
idx : 36, pred - ori : -0.197811
idx : 37, pred - ori : -0.213529
idx : 38, pred - ori : -0.241863
idx : 39, pred - ori : -0.249295
idx : 40, pred - ori : -0.232721
idx : 41, pred - ori : -0.194114
idx : 42, pred - ori : -0.198974
idx : 43, pred - ori : -0.225184
idx : 44, pred - ori : -0.246396
idx : 45, pred - ori : -0.209274
idx : 46, pred - ori : -0.160795
idx : 47, pred - ori : -0.148496
idx : 48, pred - ori : -0.127258
idx : 49, pred - ori : -0.139144
idx : 50, pred - ori : -0.135638
idx : 51, pred - ori : -0.127267
idx : 52, pred - ori : -0.159141
idx : 53, pred - ori : -0.143164
idx : 54, pred - ori : -0.122366
idx : 55, pred - ori : -0.114633
idx : 56, pred - ori : -0.095878
idx : 57, pred - ori : -0.072685
idx : 58, pred - ori : -0.116159
idx : 59, pred - ori : -0.110335
idx : 60, pred - ori : -0.116444
idx : 61, pred - ori : -0.129961
idx : 62, pred - ori : -0.124565
idx : 63, pred - ori : -0.132433
idx : 64, pred - ori : -0.155434
idx : 65, pred - ori : -0.156319
idx : 66, pred - ori : -0.143031
idx : 67, pred - ori : -0.112293
idx : 68, pred - ori : -0.122935
idx : 69, pred - ori : -0.135275
idx : 70, pred - ori : -0.115760
idx : 71, pred - ori : -0.119884
idx : 72, pred - ori : -0.094927
idx : 73, pred - ori : -0.110050
idx : 74, pred - ori : -0.136550
idx : 75, pred - ori : -0.122047
idx : 76, pred - ori : -0.100379
idx : 77, pred - ori : -0.083755
idx : 78, pred - ori : -0.091306
idx : 79, pred - ori : -0.143556
idx : 80, pred - ori : -0.144085
idx : 81, pred - ori : -0.115237
idx : 82, pred - ori : -0.099688
idx : 83, pred - ori : -0.091509
idx : 84, pred - ori : -0.145045
idx : 85, pred - ori : -0.147209
idx : 86, pred - ori : -0.154222
idx : 87, pred - ori : -0.143037
idx : 88, pred - ori : -0.091224
idx : 89, pred - ori : -0.081038
idx : 90, pred - ori : -0.078555
idx : 91, pred - ori : -0.087016
idx : 92, pred - ori : -0.078616
idx : 93, pred - ori : -0.069979
idx : 94, pred - ori : -0.091855
idx : 95, pred - ori : -0.091736
idx : 96, pred - ori : -0.094773
idx : 97, pred - ori : -0.097098
idx : 98, pred - ori : -0.100940
idx : 99, pred - ori : -0.087575
idx : 100, pred - ori : -0.112232
idx : 101, pred - ori : -0.109323
idx : 102, pred - ori : -0.085977
idx : 103, pred - ori : -0.113298
idx : 104, pred - ori : -0.106326
idx : 105, pred - ori : -0.118933
idx : 106, pred - ori : -0.142563
idx : 107, pred - ori : -0.127031
idx : 108, pred - ori : -0.111323
idx : 109, pred - ori : -0.120565
idx : 110, pred - ori : -0.113093
idx : 111, pred - ori : -0.126235
idx : 112, pred - ori : -0.111993
idx : 113, pred - ori : -0.101471
idx : 114, pred - ori : -0.109435
idx : 115, pred - ori : -0.107737
idx : 116, pred - ori : -0.099330
idx : 117, pred - ori : -0.104491
idx : 118, pred - ori : -0.104611
idx : 119, pred - ori : -0.104881
idx : 120, pred - ori : -0.098008
idx : 121, pred - ori : -0.094964
idx : 122, pred - ori : -0.102167
idx : 123, pred - ori : -0.134475
idx : 124, pred - ori : -0.135951
idx : 125, pred - ori : -0.133573
idx : 126, pred - ori : -0.123937
idx : 127, pred - ori : -0.121702
idx : 128, pred - ori : -0.197429
idx : 129, pred - ori : -0.185323
idx : 130, pred - ori : -0.166438
idx : 131, pred - ori : -0.197395
idx : 132, pred - ori : -0.208409
idx : 133, pred - ori : -0.164957
idx : 134, pred - ori : -0.143762
idx : 135, pred - ori : -0.167503
idx : 136, pred - ori : -0.166417
idx : 137, pred - ori : -0.214496
idx : 138, pred - ori : -0.283430
idx : 139, pred - ori : -0.298539
idx : 140, pred - ori : -0.269841
idx : 141, pred - ori : -0.262920
idx : 142, pred - ori : -0.304074
idx : 143, pred - ori : -0.259031
idx : 144, pred - ori : -0.272701
idx : 145, pred - ori : -0.318238
idx : 146, pred - ori : -0.342275
idx : 147, pred - ori : -0.295729
idx : 148, pred - ori : -0.307165
idx : 149, pred - ori : -0.287129
idx : 150, pred - ori : -0.288745
idx : 151, pred - ori : -0.313680
idx : 152, pred - ori : -0.376452
idx : 153, pred - ori : -0.402533
idx : 154, pred - ori : -0.391984
idx : 155, pred - ori : -0.374025
idx : 156, pred - ori : -0.404375
idx : 157, pred - ori : -0.362169
idx : 158, pred - ori : -0.373561
idx : 159, pred - ori : -0.315568
idx : 160, pred - ori : -0.345938
idx : 161, pred - ori : -0.317968
idx : 162, pred - ori : -0.326909
idx : 163, pred - ori : -0.401144
idx : 164, pred - ori : -0.373376
idx : 165, pred - ori : -0.324637
idx : 166, pred - ori : -0.293015
idx : 167, pred - ori : -0.270056
idx : 168, pred - ori : -0.306987
idx : 169, pred - ori : -0.313324
idx : 170, pred - ori : -0.337934
idx : 171, pred - ori : -0.346087
idx : 172, pred - ori : -0.354252
idx : 173, pred - ori : -0.346736
idx : 174, pred - ori : -0.414155
idx : 175, pred - ori : -0.407777
idx : 176, pred - ori : -0.387758
idx : 177, pred - ori : -0.350320
idx : 178, pred - ori : -0.353175
idx : 179, pred - ori : -0.329401
idx : 180, pred - ori : -0.340103
result_sum : 32.899952, mean(result_sum) : 0.182778
benefit : 180

 End check_performance !

Finish naver
